<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>æ·±åº¦å­¦ä¹ ä¹‹æ¢¯åº¦ä¸‹é™æ³• Part2</title>
    <url>/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%20Part2/</url>
    <content><![CDATA[<p>åœ¨Part1ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—çš„ç¥ç»ç½‘ç»œï¼Œè€Œç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦çœ‹ä¸€çœ‹å¦‚ä½•è®­ç»ƒå…¶ä¸­çš„weightï¼Œä½¿å¾—ç½‘ç»œå¯ä»¥æœ€å¥½åœ°å¯¹è¿™äº›å›¾ç‰‡è¿›è¡Œåˆ†ç±»ã€‚</p>
<h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>é¦–å…ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæŒ‡æ ‡æ¥è¡¡é‡å½“å‰ç½‘ç»œä¸­çš„weightèƒ½å¤Ÿå¤šå‡†ç¡®åœ°å®Œæˆæ•°å­—å›¾ç‰‡çš„åˆ†ç±»ã€‚æŸå¤±å‡½æ•°åšçš„å°±æ˜¯è¿™æ ·ä¸€ä»¶äº‹æƒ…ï¼š</p>
<p>$Cost(w) = $æƒé‡å¤šçƒ‚</p>
<p>$w$æ˜¯å’±ä»¬ç½‘ç»œä¸­çš„æ‰€æœ‰æƒé‡æ•°å€¼ï¼Œå°†$w$è¾“å…¥æŸå¤±å‡½æ•°ï¼Œå®ƒè¾“å‡ºä¸€ä¸ªæ•°å€¼å‘Šè¯‰æˆ‘ä»¬ï¼Œå½“å‰çš„æƒé‡åˆ°åº•æœ‰å¤šçƒ‚ã€‚é‚£ä¹ˆæŸå¤±å‡½æ•°æ˜¯æ€æ ·è¢«implementçš„å‘¢ï¼Ÿè®©æˆ‘ä»¬æ¥åº·åº·ï¼š</p>
<p><img src="/" alt="1" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%20Part2/1.png"></p>
<p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—æ¯ä¸ªç»“ç‚¹è¾“å‡ºçš„ç»“æœä¸å…¶åº”è¯¥æœ‰çš„æ­£ç¡®å€¼çš„å¹³æ–¹å’Œçš„æ€»å’Œæ¥å¾—çŸ¥å½“å‰æƒé‡çš„ç³Ÿç³•ç¨‹åº¦ã€‚</p>
<h2 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h2><p>ç„¶é¹…ï¼ŒçŸ¥é“äº†ç³Ÿç³•ç¨‹åº¦ï¼Œæˆ‘ä»¬å¦‚ä½•æ®æ­¤è°ƒæ•´æƒé‡ï¼Œè®©ç»“æœä¸é‚£ä¹ˆç³Ÿç³•å‘¢ï¼Ÿè¿™æ—¶å€™å°±è¦ç”¨åˆ°æ¢¯åº¦ä¸‹é™ã€‚</p>
<p><img src="/" alt="2" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%20Part2/2.png"></p>
<p>ä¹‹æ‰€ä»¥å«æ¢¯åº¦ä¸‹é™ï¼Œæ˜¯å› ä¸ºè¿™ä¸ªæ–¹æ³•ç”¨åˆ°äº†æ¢¯åº¦ã€‚æˆ‘ä»¬çŸ¥é“ï¼ŒæŸä¸ªå‡½æ•°çš„æŸä¸€ç‚¹çš„æ¢¯åº¦æ–¹å‘äº‹å®ä¸Šæ˜¯è¿™ä¸ªå‡½æ•°åœ¨è¿™ä¸€ç‚¹çš„æ•°å€¼ä¸Šå‡å¾—æœ€å¿«çš„æ–¹å‘ã€‚åˆ©ç”¨è¿™ä¸€æ€§è´¨ï¼Œæˆ‘ä»¬è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œç„¶åå¾€åæ–¹å‘èµ°ï¼Œå°±æ˜¯ä½¿å¾—æŸå¤±å‡½æ•°ä¸‹é™æœ€å¿«çš„æ–¹å‘ã€‚è€Œæ¢¯åº¦ä¸‹é™ï¼Œäº‹å®ä¸Šå°±æ˜¯ä¸åœåœ°é‡å¤ä»¥ä¸‹è¿‡ç¨‹ï¼š</p>
<ul>
<li>è®¡ç®—æŸå¤±å‡½æ•°åœ¨æŸä¸€ç‚¹çš„æ¢¯åº¦</li>
<li>å‘æ¢¯åº¦ç›¸åçš„æ–¹å‘æ›´æ–°æƒé‡</li>
</ul>
<p><img src="/" alt="3" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%20Part2/3.png"><br>äº‹å®ä¸Šï¼Œæ¢¯åº¦çš„æ­£è´Ÿï¼Œå‘Šè¯‰æˆ‘ä»¬å¾€å“ªä¸ªæ–¹å‘èµ°å¯ä»¥ä½¿å¾—æˆ‘ä»¬è·å¾—æ›´å°çš„costï¼Œè€Œæ¢¯åº¦çš„å¤§å°åˆ™å‘Šè¯‰æˆ‘ä»¬æ¯ä¸€é¡¹å¯¹äºæ¢¯åº¦å¤§å°å˜åŒ–çš„å½±å“ç¨‹åº¦å¤§å°ã€‚æ¯”å¦‚æŸä¸€é¡¹çš„æ¢¯åº¦å¤§ï¼Œé‚£ä¹ˆæ›´æ–°å®ƒç›¸æ¯”äºæ›´æ–°åˆ«äººæ›´èƒ½ä½¿å¾—è®¡ç®—å‡ºçš„æŸå¤±å€¼å‘ç”Ÿå˜åŒ–ã€‚</p>
<h2 id="é¢å¤–èµ„æ–™"><a href="#é¢å¤–èµ„æ–™" class="headerlink" title="é¢å¤–èµ„æ–™"></a>é¢å¤–èµ„æ–™</h2><p>åœ¨å…³å¿ƒæœºå™¨æ€ä¹ˆå­¦ä¹ ä¹‹å‰ï¼Œå’±ä»¬å…ˆæ¥çœ‹çœ‹æˆ‘ä»¬è‡ªå·±åº”è¯¥æ€ä¹ˆå­¦ï¼Œè¿™ä¸ªç½‘é¡µä¸­å¯¹è®­ç»ƒä¸€ä¸ªæ•°å­—å›¾ç‰‡åˆ†ç±»å™¨è¿›è¡Œäº†è¯¦ç»†çš„ä»‹ç»ï¼š<a href="http://neuralnetworksanddeeplearning.com/chap1.htmlã€‚" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/chap1.htmlã€‚</a></p>
<p>è§†é¢‘åœ°å€ï¼š<a href="https://www.bilibili.com/video/BV1Ux411j7ri" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1Ux411j7ri</a></p>
]]></content>
      <tags>
        <tag>3Blue1Brown</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title>æ·±åº¦å­¦ä¹ ä¹‹ç¥ç»ç½‘ç»œçš„ç»“æ„ Part1</title>
    <url>/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/</url>
    <content><![CDATA[<h2 id="ç½‘ç»œç»“æ„"><a href="#ç½‘ç»œç»“æ„" class="headerlink" title="ç½‘ç»œç»“æ„"></a>ç½‘ç»œç»“æ„</h2><p>å‡è®¾ç°åœ¨æˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«æ‰‹å†™æ•°å­—å›¾ç‰‡ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€ä¸ºç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœº(MLP)è®­ç»ƒï¼Œå®šä¹‰ä¸€ä¸ªè¾“å…¥å±‚ï¼Œä¸¤ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ã€‚æˆ‘ä»¬å°†28x28çš„å›¾ç‰‡â€œæ‹‰ç›´â€ï¼Œå› æ­¤è¾“å…¥å±‚æœ‰784ä¸ªç»“ç‚¹ã€‚è€Œè¾“å‡ºå±‚çš„æ˜¯ä¸ªç»“ç‚¹ä»£è¡¨æ˜¯åä¸ªæ•°å­—ä¸­æŸä¸ªæ•°å­—çš„å¯èƒ½æ€§ã€‚</p>
<p><img src="/" alt="Screen Shot 2020-03-31 at 12.07.48 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/1.png"></p>
<h2 id="ç½‘ç»œè¾“å…¥"><a href="#ç½‘ç»œè¾“å…¥" class="headerlink" title="ç½‘ç»œè¾“å…¥"></a>ç½‘ç»œè¾“å…¥</h2><p><img src="/" alt="Screen Shot 2020-03-31 at 12.08.41 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/2.png"></p>
<p>è¾“å…¥å€¼æ˜¯å›¾ç‰‡ä¸­æŸä¸ªåƒç´ çš„ç°åº¦ï¼Œå–å€¼èŒƒå›´åœ¨[0,1]ï¼Œ0ä»£è¡¨å…¨é»‘ï¼Œ1ä»£è¡¨å…¨ç™½ï¼Œè¾“å…¥æŸä¸ªç»“ç‚¹çš„æ•°å€¼å«åšæ¿€æ´»å€¼ï¼ˆActivationï¼‰ã€‚</p>
<h2 id="ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦éšè—å±‚ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦éšè—å±‚ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦éšè—å±‚ï¼Ÿ"></a>ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦éšè—å±‚ï¼Ÿ</h2><p>é‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦æå¾ˆå¤šå±‚è€Œä¸æ˜¯å°±åªæœ‰ä¸€ä¸ªéšè—å±‚å‘¢ï¼Ÿ</p>
<p><img src="/" alt="Screen Shot 2020-03-31 at 12.10.56 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/3.png"></p>
<p><img src="/" alt="Screen Shot 2020-03-31 at 12.11.20 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/4.png">  </p>
<p>å…ˆæ¥çœ‹ä¸€çœ‹è¿™äº›æ•°å­—ï¼Œä»–ä»¬å„è‡ªç”±ä¸€äº›ç¬”ç”»ç»„æˆã€‚</p>
<p><img src="/" alt="Screen Shot 2020-03-31 at 12.11.37 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/5.png"></p>
<p>å¯¹äºéšè—å±‚ä¸­çš„ç»“ç‚¹æ¥è¯´ï¼Œä¹Ÿè®¸æ¯ä¸ªç»“ç‚¹è´Ÿè´£ä¸€ç§ç¬”åˆ’çš„åˆ¤æ–­ã€‚è€Œæˆ‘ä»¬æ”¾ç½®å¤šä¸ªéšè—å±‚ï¼Œå°±å¯ä»¥ç»„åˆåˆ¤æ–­å¤šç§ç¬”åˆ’ï¼Œè¾¾åˆ°è¯†åˆ«æ•°å­—çš„ç›®çš„ã€‚</p>
<h2 id="æƒé‡æ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Ÿ"><a href="#æƒé‡æ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Ÿ" class="headerlink" title="æƒé‡æ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Ÿ"></a>æƒé‡æ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Ÿ</h2><p><img src="/" alt="Screen Shot 2020-03-31 at 12.13.10 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/6.png"></p>
<p>æƒé‡å…¶å®å†³å®šäº†æŸä¸ªç»“ç‚¹çš„å€¼å—ä¸Šä¸€å±‚ä¸­å„ç»“ç‚¹çš„å½±å“ç¨‹åº¦ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå°±æ˜¯æŸæ•°å­—ç”±å„ç¬”åˆ’ç»„æˆçš„ç¨‹åº¦ã€‚</p>
<h2 id="æ¿€æ´»å‡½æ•°çš„ä½œç”¨"><a href="#æ¿€æ´»å‡½æ•°çš„ä½œç”¨" class="headerlink" title="æ¿€æ´»å‡½æ•°çš„ä½œç”¨"></a>æ¿€æ´»å‡½æ•°çš„ä½œç”¨</h2><p><img src="/" alt="Screen Shot 2020-03-31 at 12.15.27 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/7.png"></p>
<p>è¿™æ˜¯ä¸€ä¸ªSigmoidå‡½æ•°ï¼Œå®ƒæ˜¯ä¸€ä¸ªæœ€ä¸ºBasicçš„æ¿€æ´»å‡½æ•°ï¼Œå°†èŒƒå›´ä¸ºè´Ÿæ— ç©·åˆ°æ­£æ— ç©·çš„è¾“å…¥æ˜ å°„åˆ°èŒƒå›´ä¸º(0,1)çš„è¾“å‡ºã€‚</p>
<h2 id="æ”¾åœ¨ä¸€èµ·è§‚å¯Ÿ"><a href="#æ”¾åœ¨ä¸€èµ·è§‚å¯Ÿ" class="headerlink" title="æ”¾åœ¨ä¸€èµ·è§‚å¯Ÿ"></a>æ”¾åœ¨ä¸€èµ·è§‚å¯Ÿ</h2><p><img src="/" alt="Screen Shot 2020-03-31 at 12.16.44 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/8.png"></p>
<p>æ”¾åœ¨ä¸€èµ·çœ‹ï¼Œæƒé‡å†³å®šæŸç¥ç»å…ƒå…³æ³¨ä¸Šä¸€å±‚çš„å“ªäº›ç¥ç»å…ƒï¼Œè€Œbiaså†³å®šäº†åŠ æƒå’Œéœ€è¦å¤šå¤§ï¼Œæ‰å¯ä»¥æ¿€æ´»æ­¤ç¥ç»å…ƒã€‚è€Œæ¿€æ´»å‡½æ•°äº‹å®ä¸Šè¡¡é‡äº†åŠ æƒå’Œåˆ°åº•æœ‰å¤šæ­£ã€‚<img src="/" alt="Screen Shot 2020-03-31 at 12.18.37 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/9.png"></p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒæŸå±‚ä¸ŠæŸä¸ªç»“ç‚¹çš„å€¼æ˜¯å…¶ä¸Šä¸€å±‚ç»“ç‚¹å€¼çš„åŠ æƒå’Œï¼Œå› æ­¤å¯¹äºç¬¬äºŒå±‚çš„æ¯ä¸ªç»“ç‚¹æ¥è¯´ï¼Œå…¶éƒ½æœ‰å¯¹åº”çš„784ä¸ªæƒé‡ï¼Œè€Œæ¯ä¸ªç»“ç‚¹åˆéƒ½æœ‰ä¸€ä¸ªbiasï¼Œå› æ­¤å¯¹äºç¬¬äºŒå±‚çš„æ‰€æœ‰ç»“ç‚¹æ¥è¯´ï¼Œæ€»å…±æœ‰784x16ä¸ªweightä»¥åŠ16ä¸ªbiasã€‚</p>
<h2 id="å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°"><a href="#å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°" class="headerlink" title="å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°"></a>å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°</h2><p><img src="/" alt="Screen Shot 2020-03-31 at 12.22.08 PM" class="lazyload" data-src="/2020/03/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%20Part1/10.png"></p>
<p>æ¿€æ´»å‡½æ•°çš„ä»»åŠ¡äº‹å®ä¸Šæ˜¯æ¨¡æ‹Ÿäººè„‘ä¸­çš„ç¥ç»å…ƒï¼Œåœ¨è¾“å…¥è¾¾åˆ°æŸç§æ•°å€¼æ—¶ï¼Œæ‰å‘åè¾“å‡ºã€‚å®éªŒè¡¨æ˜ï¼ŒSigmoidå‡½æ•°çš„æ¿€æ´»æ•ˆæœå¹¶ä¸å¥½ã€‚ä¸å…¶ç›¸æ¯”ï¼ŒReluçš„æ¿€æ´»</p>
<p>åŸè§†é¢‘é“¾æ¥ï¼š<a href="https://www.bilibili.com/video/BV1bx411M7Zx" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1bx411M7Zx</a></p>
]]></content>
      <tags>
        <tag>3Blue1Brown</tag>
        <tag>æ·±åº¦å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title>argparserç®€æ˜æ•™ç¨‹</title>
    <url>/2020/03/25/argparser%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h2><p>argparseræ˜¯åœ¨ä½¿ç”¨Pythonç¼–ç¨‹æ—¶é¦–é€‰çš„å‘½ä»¤è¡Œå‚æ•°è§£æå™¨ã€‚è¯¥åº“æ˜¯Pythonè¯­è¨€è‡ªå¸¦çš„åº“ï¼Œå®ƒè‡ªåŠ¨å†³å®šå¦‚ä½•ä»<code>sys.argv</code>ä¸­è§£æå‡ºå„ç§å‘½ä»¤è¡Œå‚æ•°ã€‚æ ¹æ®ç”¨æˆ·æŒ‡å®šçš„å‚æ•°ï¼Œargparserè‡ªåŠ¨ç”Ÿæˆå¸®åŠ©ä¿¡æ¯ï¼Œå¹¶èƒ½åœ¨ç”¨æˆ·ä¼ å…¥æ— æ•ˆå‚æ•°æ—¶æç¤ºç”¨æˆ·ã€‚</p>
<h2 id="åˆ›å»ºè§£æå™¨"><a href="#åˆ›å»ºè§£æå™¨" class="headerlink" title="åˆ›å»ºè§£æå™¨"></a>åˆ›å»ºè§£æå™¨</h2><p>åœ¨è¿›ä¸€æ­¥æŒ‡å®šè§£æå™¨çš„å„ç§å‚æ•°å‰ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆå®ä¾‹åŒ–ä¸€ä¸ªè§£æå™¨,é€šè¿‡descriptioné€‰é¡¹ï¼Œå¯ä»¥å‘Šè¯‰ç”¨æˆ·è¿™ä¸ªç¨‹åºæ˜¯å¹²ä»€ä¹ˆçš„ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Process some integers.'</span>)</span><br></pre></td></tr></table></figure>



<h2 id="æ·»åŠ å¿…é€‰å‚æ•°"><a href="#æ·»åŠ å¿…é€‰å‚æ•°" class="headerlink" title="æ·»åŠ å¿…é€‰å‚æ•°"></a>æ·»åŠ å¿…é€‰å‚æ•°</h2><p>åœ¨æˆ‘ä»¬ç¼–ç¨‹æ—¶ï¼Œæœ‰æ—¶éœ€è¦åœ¨å‘½ä»¤è¡Œä¸­å‘Pythonç¨‹åºä¼ å…¥ä¸€äº›å‚æ•°ï¼Œä¸”è¿™äº›å‚æ•°æ˜¯å¿…é€‰çš„ï¼Œæ²¡æœ‰è¿™äº›å‚æ•°ï¼Œç¨‹åºå°†æ— æ³•æ­£å¸¸è¿è¡Œã€‚</p>
<p>å‡è®¾ç°åœ¨æˆ‘ä»¬éœ€è¦å†™ä¸€ä¸ªç¨‹åºï¼Œä½¿å…¶å¯ä»¥è¯»å…¥å‘½ä»¤è¡Œä¸­ç”¨æˆ·æŒ‡å®šçš„ä¸€ä¸ªæ•°å­—ï¼Œç„¶åå°†è¯¥æ•°å­—çš„å¹³æ–¹æ‰“å°å‡ºæ¥ã€‚ç¼–å†™ç¨‹åºprog.pyï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"square"</span>, help=<span class="string">"display a square of a given number"</span>,</span><br><span class="line">                    type=int)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.square**<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>åœ¨ä¸Šæ–¹çš„ç¨‹åºä¸­ï¼Œæˆ‘ä»¬é€šè¿‡<code>add_argument</code>å‘è§£æå™¨ä¸­æ·»åŠ äº†ä¸€ä¸ªå¿…é€‰å‚æ•°<code>&quot;square&quot;</code>ï¼Œä¸”è¯¥å‚æ•°çš„å¸®åŠ©ä¿¡æ¯ä¸º<code>help=&quot;display a square of a given number&quot;</code>ï¼Œè¯¥å‚æ•°çš„ç±»å‹ä¸º<code>int</code>ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œåˆ™è¯»å–åˆ°çš„å‚æ•°å°†è¢«è®¤ä¸ºæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼‰ã€‚é€šè¿‡<code>args = parser.parse_args()</code>å¯¹ä¼ å…¥çš„å‚æ•°è¿›è¡Œè§£æï¼Œé€šè¿‡<code>args.square</code>è¯»å–ä¼ å…¥çš„<code>square</code>æ•°å€¼ã€‚</p>
<p>ç°åœ¨ï¼Œè®©å’±ä»¬è¿è¡Œä¸€ä¸‹ä¸Šé¢å†™çš„é‚£ä¸ªç¨‹åºï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python3 prog.py 4 <span class="comment">#ä¼ å…¥æ­£ç¡®å‚æ•°</span></span><br><span class="line">16</span><br><span class="line">$ python3 prog.py four <span class="comment">#ä¼ å…¥é”™è¯¯å‚æ•°ï¼Œè§£æå™¨æŠ¥é”™</span></span><br><span class="line">usage: prog.py [-h] square</span><br><span class="line">prog.py: error: argument square: invalid int value: <span class="string">'four'</span></span><br></pre></td></tr></table></figure>

<p>å¯ä»¥çœ‹åˆ°ï¼Œé€šè¿‡å‘½ä»¤è¡Œè¿è¡Œè¯¥ç¨‹åºï¼Œå¹¶æŒ‡å®š<code>square</code>ä¸º4ï¼Œç¨‹åºæ‰“å°å‡ºäº†æ­£ç¡®çš„ç»“æœ16ã€‚</p>
<h2 id="æ·»åŠ å¯é€‰å‚æ•°"><a href="#æ·»åŠ å¯é€‰å‚æ•°" class="headerlink" title="æ·»åŠ å¯é€‰å‚æ•°"></a>æ·»åŠ å¯é€‰å‚æ•°</h2><p>åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¼šå¦‚ä½•å‘è§£æå™¨æ·»åŠ å¿…é€‰å‚æ•°ï¼Œç„¶é¹…ï¼Œæœ‰æ—¶å€™æˆ‘ä»¬çš„å‚æ•°å¹¶ä¸æ˜¯å¿…é€‰çš„ï¼Œæˆ–è€…ï¼Œå®ƒåªæ˜¯æŸç§å¼€å…³ï¼Œé‚£å’±ä»¬å’‹åŠå‘¢ï¼Ÿã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ å¯é€‰å‚æ•°æ¥è§£å†³é—®é¢˜ã€‚</p>
<p>æˆ‘ä»¬ç¼–å†™æµ‹è¯•æ–‡ä»¶parser_test.py:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--çé€¼é€¼"</span>, help=<span class="string">"è¾“å‡ºä¿¡æ¯æ›´åŠ è¯¦ç»†"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼:</span><br><span class="line">    print(<span class="string">"çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€"</span>)</span><br></pre></td></tr></table></figure>

<p>è¿è¡Œè¯¥æ–‡ä»¶ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py --çé€¼é€¼ 1 <span class="comment">#ä¼ å…¥å‚æ•°ï¼Œæ­£å¸¸</span></span><br><span class="line">çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€</span><br><span class="line">$ python parser_test --çé€¼é€¼ <span class="comment">#æ²¡ä¼ å…¥å‚æ•°ï¼ŒæŠ¥é”™</span></span><br><span class="line">python: can<span class="string">'t open file '</span>parser_test<span class="string">': [Errno 2] No such file or directory</span></span><br></pre></td></tr></table></figure>

<h3 id="ä½œä¸ºâ€œå¼€å…³â€çš„å¯é€‰å‚æ•°"><a href="#ä½œä¸ºâ€œå¼€å…³â€çš„å¯é€‰å‚æ•°" class="headerlink" title="ä½œä¸ºâ€œå¼€å…³â€çš„å¯é€‰å‚æ•°"></a>ä½œä¸ºâ€œå¼€å…³â€çš„å¯é€‰å‚æ•°</h3><p>åœ¨ä¸Šæ–¹çš„ä¾‹å­ä¸­ï¼Œéœ€è¦ä¼ å…¥ä¸€ä¸ªæ²¡æœ‰ç”¨çš„å‚æ•°æ‰èƒ½ä½¿å…¶æ­£å¸¸è¿è¡Œï¼Œä½†æ˜¯å’±ä»¬å…¶å®æ˜¯æƒ³æŠŠ<code>--çé€¼é€¼</code>ä½œä¸ºä¸€ä¸ªå¼€å…³ï¼Œå¦‚æœæŒ‡å®šè¯¥é€‰é¡¹ï¼Œç¨‹åºå°±ä»¥çé€¼é€¼æ¨¡å¼è¿è¡Œï¼Œå¦‚æœæ²¡æŒ‡å®šå°±ä»¥æ­£å¸¸æ¨¡å¼è¿è¡Œï¼Œ<code>çé€¼é€¼</code>è¿™ä¸ªå‚æ•°å…¶å®æ˜¯å……å½“ä¸€ä¸ªboolå˜é‡ï¼Œä¸æ˜¯<code>True</code>å°±æ˜¯<code>False</code>ã€‚å’±ä»¬å¯ä»¥æŠŠä¸Šé¢çš„ç¨‹åºæ”¹æ”¹ï¼Œå†™æˆä¸‹é¢è¿™æ ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"--çé€¼é€¼"</span>, help=<span class="string">"è¾“å‡ºä¿¡æ¯æ›´åŠ è¯¦ç»†"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼:</span><br><span class="line">    print(<span class="string">"çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€"</span>)</span><br></pre></td></tr></table></figure>

<p>ä¸Šæ–¹ç¨‹åºé€šè¿‡æ·»åŠ <code>action=&quot;store_true&quot;</code>å°†<code>çé€¼é€¼</code>è¿™ä¸ªå‚æ•°æŒ‡å®šæˆä¸€ä¸ªboolå‚æ•°ï¼Œè¿è¡Œè¯¥æ–‡ä»¶ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸‹ç»“æœï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py --çé€¼é€¼</span><br><span class="line">çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€</span><br><span class="line">$ python parse_test.py --çé€¼é€¼ 1</span><br><span class="line">usage: parse_test.py [-h] [--çé€¼é€¼]</span><br><span class="line">parse_test.py: error: unrecognized arguments: 1</span><br></pre></td></tr></table></figure>

<p>è¿™æ ·ä»¥æ¥ï¼Œ<code>çé€¼é€¼</code>å‚æ•°å°±å˜æˆäº†ä¸€ä¸ªå¼€å…³ï¼Œè€Œç”¨æˆ·å¦‚æœå¤šä¼ å…¥æ— å…³å‚æ•°å°±ä¼šæŠ¥é”™ã€‚äº‹å®ä¸Šï¼Œåœ¨ä½¿ç”¨<code>action=&quot;store_true&quot;</code>é€‰é¡¹åï¼Œå½“ç”¨æˆ·ä¼ å…¥<code>--çé€¼é€¼</code>é€‰é¡¹æ—¶ï¼Œ<code>çé€¼é€¼</code>è¿™ä¸ªå‚æ•°å°±ä¸º<code>True</code>ï¼Œè€Œå¦‚æœæ²¡æœ‰ä¼ å…¥è¿™ä¸ªé€‰é¡¹ï¼Œå‚æ•°å€¼ä¸º<code>False</code>ã€‚</p>
<h3 id="æ·»åŠ å¯é€‰å‚æ•°çš„ç¼©å†™"><a href="#æ·»åŠ å¯é€‰å‚æ•°çš„ç¼©å†™" class="headerlink" title="æ·»åŠ å¯é€‰å‚æ•°çš„ç¼©å†™"></a>æ·»åŠ å¯é€‰å‚æ•°çš„ç¼©å†™</h3><p>åœ¨ä¸Šæ–¹ğŸŒ°ä¸­ï¼Œæˆ‘ä»¬å°†<code>--çé€¼é€¼</code>ä½œä¸ºå¯é€‰å‚æ•°ï¼Œä½†æœ‰æ—¶å€™æˆ‘ä»¬æ¯”è¾ƒæ‡’ï¼Œä¸æƒ³è¦å†™â€œçé€¼é€¼â€è¿™ä¸‰ä¸ªå­—ã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©æ·»åŠ å¯é€‰å‚æ•°çš„ç¼©å†™ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>, help=<span class="string">"è¾“å‡ºä¿¡æ¯æ›´åŠ è¯¦ç»†"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼:</span><br><span class="line">    print(<span class="string">"çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€"</span>)</span><br></pre></td></tr></table></figure>

<p>è¿è¡Œç»“æœ:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py -ç</span><br><span class="line">çé€¼é€¼æ¨¡å¼å·²è¢«æ‰“å¼€</span><br></pre></td></tr></table></figure>

<p>ä»ç»“æœå¯ä»¥çœ‹å‡ºï¼Œé€šè¿‡æ·»åŠ â€-çâ€ï¼Œæˆ‘ä»¬åªå†™ä¸€ä¸ªå­—å°±èƒ½æ‰“å¼€çé€¼é€¼å¼€å…³ã€‚</p>
<h2 id="ç»“åˆå¯é€‰å‚æ•°ä¸å¿…é€‰å‚æ•°"><a href="#ç»“åˆå¯é€‰å‚æ•°ä¸å¿…é€‰å‚æ•°" class="headerlink" title="ç»“åˆå¯é€‰å‚æ•°ä¸å¿…é€‰å‚æ•°"></a>ç»“åˆå¯é€‰å‚æ•°ä¸å¿…é€‰å‚æ•°</h2><p>ç°åœ¨å’±ä»¬æŠŠâ€œæ·»åŠ å¿…é€‰å‚æ•°â€éƒ¨åˆ†çš„ç¨‹åºä¸â€œæ·»åŠ å¯é€‰å‚æ•°â€éƒ¨åˆ†çš„ä»£ç æ”¾åˆ°ä¸€èµ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"square"</span>, type=int,</span><br><span class="line">                    help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>, help=<span class="string">"è¾“å‡ºä¿¡æ¯æ›´åŠ è¯¦ç»†"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square**<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼:</span><br><span class="line">    print(<span class="string">"the square of &#123;&#125; equals &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure>

<p>è¿è¡Œç»“æœ:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py</span><br><span class="line">usage: parse_test.py [-h] [-ç] square</span><br><span class="line">parse_test.py: error: the following arguments are required: square</span><br><span class="line">$ python parse_test.py -ç</span><br><span class="line">usage: parse_test.py [-h] [-ç] square</span><br><span class="line">parse_test.py: error: the following arguments are required: square</span><br><span class="line">$ python parse_test.py -ç 4</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure>

<h3 id="æ·»åŠ â€œå‰¯â€å¼€å…³"><a href="#æ·»åŠ â€œå‰¯â€å¼€å…³" class="headerlink" title="æ·»åŠ â€œå‰¯â€å¼€å…³"></a>æ·»åŠ â€œå‰¯â€å¼€å…³</h3><p>è™½ç„¶å’±ä»¬åœ¨ä¸Šé¢æ·»åŠ äº†<code>--çé€¼é€¼</code>å¼€å…³æ¥å†³å®šç¨‹åºè¾“å‡ºä¿¡æ¯çš„è¯¦ç»†ç¨‹åº¦ï¼Œä½†æœ‰æ—¶ï¼Œæˆ‘ä»¬æ·»åŠ çš„å¼€å…³ä¹Ÿéœ€è¦å‚æ•°ã€‚ä¸¾ä¸ªğŸŒ°ï¼Œç°åœ¨æˆ‘ä»¬ä¸ä»…éœ€è¦æŒ‡å®šç¨‹åºæ˜¯å¦è¦çé€¼é€¼ï¼Œæˆ‘ä»¬è¿˜è¦æŒ‡å®šå…¶çé€¼é€¼çš„ç¨‹åº¦ï¼Œæˆ‘ä»¬å¸Œæœ›ç¨‹åºçš„çé€¼é€¼åº¦ä¸º0ã€1æˆ–2ï¼Œçé€¼é€¼ç¨‹åº¦éšæ•°å­—å¤§å°è€Œå¢åŠ ã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"square"</span>, type=int,</span><br><span class="line">                    help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>, type=int, choices=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                    help=<span class="string">"increase output verbosity"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square**<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼ == <span class="number">2</span>:</span><br><span class="line">    print(<span class="string">"the square of &#123;&#125; equals &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">elif</span> args.çé€¼é€¼ == <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"&#123;&#125;^2 == &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure>

<p>é€šè¿‡åœ¨æ·»åŠ å‚æ•°æ—¶åŠ å…¥<code>choices=[0, 1, 2]</code>å°†çé€¼é€¼ç¨‹åº¦çš„ä¼ å…¥å‚æ•°é™åˆ¶åœ¨è¿™ä¸‰ä¸ªæ•°å­—ä»¥é˜²ç”¨æˆ·ä¼ è¿›æ¥ä¸€äº›å¥‡å¥‡æ€ªæ€ªçš„ä¸œè¥¿ï¼Œåœ¨ä¸‹æ–¹é€šè¿‡if elseæ¥åŒºåˆ†ç”¨æˆ·ä¼ å…¥çš„ä¸åŒçé€¼é€¼ç¨‹åº¦ï¼Œå¹¶ä»¥ç›¸åº”ç¨‹åº¦è¾“å‡ºç»“æœã€‚</p>
<p>ç»“æœ:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py 4 -ç 3 <span class="comment">#ä¸åœ¨choicesä¸­ï¼Œå› æ­¤æŠ¥é”™ã€‚</span></span><br><span class="line">usage: parse_test.py [-h] [-ç &#123;0,1,2&#125;] square</span><br><span class="line">parse_test.py: error: argument -ç/--çé€¼é€¼: invalid choice: 3 (choose from 0, 1, 2)</span><br><span class="line">$ python parse_test.py 4 -h</span><br><span class="line">usage: parse_test.py [-h] [-ç &#123;0,1,2&#125;] square</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  square                display a square of a given number</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --<span class="built_in">help</span>            show this <span class="built_in">help</span> message and <span class="built_in">exit</span></span><br><span class="line">  -ç &#123;0,1,2&#125;, --çé€¼é€¼ &#123;0,1,2&#125;</span><br><span class="line">                        increase output verbosity</span><br><span class="line">$ python parse_test.py 4 -ç 1<span class="comment">#ä»¥ä¸€çº§çé€¼é€¼ç¨‹åº¦è¾“å‡º</span></span><br><span class="line">4^2 == 16</span><br><span class="line">(base) butyuhao@Yuhaos-MBP <span class="built_in">test</span> %</span><br></pre></td></tr></table></figure>

<p>è¯•è¯•ä¸Šè¿˜æœ‰å¦ä¸€ç§æŒ‡å®šçé€¼é€¼ç¨‹åº¦çš„æ–¹å¼ï¼Œé‚£å°±æ˜¯ç”¨é‡å¤å‚æ•°æ¬¡æ•°çš„æ–¹å¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"square"</span>, type=int,</span><br><span class="line">                    help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>,action=<span class="string">"count"</span>,</span><br><span class="line">                    help=<span class="string">"increase output verbosity"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square**<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼ &gt;= <span class="number">2</span>:</span><br><span class="line">    print(<span class="string">"the square of &#123;&#125; equals &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">elif</span> args.çé€¼é€¼ == <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"&#123;&#125;^2 == &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure>

<p>é€šè¿‡æ·»åŠ <code>action=&quot;count&quot;</code>é€‰é¡¹ï¼Œè§£æå™¨å°†å­˜å‚¨è¯¥å‚æ•°åœ¨ä¼ å…¥æ—¶çš„é‡å¤æ¬¡æ•°ï¼Œè¿™æ ·ä¸€æ¥å°±å¯ä»¥é€šè¿‡é‡å¤æ¬¡æ•°æ¥è¡¨ç¤ºçé€¼é€¼ç¨‹åº¦ã€‚</p>
<p>è¾“å‡ºï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py -ç 4</span><br><span class="line">4^2 == 16</span><br><span class="line">$ python parse_test.py -çç 4</span><br><span class="line">the square of 4 equals 16</span><br><span class="line">$ python parse_test.py -ççç 4</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure>

<p>åœ¨ç»“æœä¸­å¯ä»¥çœ‹åˆ°ï¼Œéšç€å‚æ•°é‡å¤æ¬¡æ•°çš„æ”¹å˜ï¼Œè¾“å‡ºä¹Ÿä½œç›¸åº”æ”¹å˜ã€‚</p>
<p>ä¸è¿‡ï¼Œä½ çœŸçš„è§‰å¾—è¿™æ ·å°±è¡Œäº†ä¹ˆï¼Ÿä½ è¿˜æ˜¯å¤ªnaiveäº†ï¼Œå¦‚æœè¿™æ—¶å€™ç”¨æˆ·ä¸æŒ‡å®šè¿™ä¸ªå‚æ•°å°±ä¼šæŠ¥é”™ï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py 4</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"parse_test.py"</span>, line 9, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">if</span> args.çé€¼é€¼ &gt;= 2:</span><br><span class="line">TypeError: <span class="string">'&gt;='</span> not supported between instances of <span class="string">'NoneType'</span> and <span class="string">'int'</span></span><br></pre></td></tr></table></figure>

<p>å¦‚æœç”¨æˆ·ä¸ä¼ å…¥è¿™ä¸ªå‚æ•°ï¼Œåˆ™è¯¥å‚æ•°å–å€¼å°†ä¸ºNoneï¼Œè€Œ&gt;=æ“ä½œç¬¦ä¸å¯ä»¥æ¯”è¾ƒä¸€ä¸ªNoneå’Œä¸€ä¸ªæ•°å­—ï¼Œå› æ­¤æŠ¥é”™ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸ºè¯¥å‚æ•°æŒ‡å®šé»˜è®¤å€¼è§£å†³è¯¥é—®é¢˜ï¼Œè¿™æ ·åœ¨ç”¨æˆ·ä¸æŒ‡å®šè¯¥å‚æ•°æ—¶ï¼Œè¯¥å‚æ•°ä¸ºé»˜è®¤å€¼ï¼Œé€šè¿‡æ·»åŠ defaultå‚æ•°æŒ‡å®šï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">"square"</span>, type=int,</span><br><span class="line">                    help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>,action=<span class="string">"count"</span>,</span><br><span class="line">                    default=<span class="number">0</span>, help=<span class="string">"increase output verbosity"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square**<span class="number">2</span></span><br><span class="line"><span class="keyword">if</span> args.çé€¼é€¼ &gt;= <span class="number">2</span>:</span><br><span class="line">    print(<span class="string">"the square of &#123;&#125; equals &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">elif</span> args.çé€¼é€¼ == <span class="number">1</span>:</span><br><span class="line">    print(<span class="string">"&#123;&#125;^2 == &#123;&#125;"</span>.format(args.square, answer))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure>

<h2 id="äº’æ–¥çš„å‚æ•°"><a href="#äº’æ–¥çš„å‚æ•°" class="headerlink" title="äº’æ–¥çš„å‚æ•°"></a>äº’æ–¥çš„å‚æ•°</h2><p>æœ‰æ—¶ï¼Œå’±ä»¬éœ€è¦è®©ç”¨æˆ·çŸ¥é“ï¼ŒæŸäº›å‚æ•°é—´åªèƒ½é€‰ä¸€ä¸ªã€‚ä¸¾ä¸ªğŸŒ°ï¼Œæ­¤æ—¶æˆ‘ä»¬ä¸ä»…æœ‰<code>--çé€¼é€¼</code>é€‰é¡¹ï¼Œè¿˜æœ‰<code>--å®‰é™</code>é€‰é¡¹ã€‚å¾ˆæ˜æ˜¾ï¼Œä½ å¹¶ä¸èƒ½æ—¢è®©ç¨‹åºçé€¼é€¼ï¼Œåˆè®©ç¨‹åºå®‰é™ï¼Œè¿™å¾ˆæ˜æ˜¾ä¼šè®©ä½ çš„ç¨‹åºç²¾ç¥åˆ†è£‚ã€‚è¿™æ—¶å€™æˆ‘ä»¬éœ€è¦å°†å®ƒä»¬è®¾ç½®ä¸ºäº’æ–¥ï¼Œè¿™æ ·ç”¨æˆ·åªèƒ½ä»ä¸­é€‰ä¸€ä¸ªæŒ‡å®šã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">group = parser.add_mutually_exclusive_group()</span><br><span class="line">group.add_argument(<span class="string">"-ç"</span>, <span class="string">"--çé€¼é€¼"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">group.add_argument(<span class="string">"-å®‰"</span>, <span class="string">"--å®‰é™"</span>, action=<span class="string">"store_true"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"x"</span>, type=int, help=<span class="string">"the base"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"y"</span>, type=int, help=<span class="string">"the exponent"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.x**args.y</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.å®‰é™:</span><br><span class="line">    print(answer)</span><br><span class="line"><span class="keyword">elif</span> args.çé€¼é€¼:</span><br><span class="line">    print(<span class="string">"&#123;&#125; to the power &#123;&#125; equals &#123;&#125;"</span>.format(args.x, args.y, answer))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">"&#123;&#125;^&#123;&#125; == &#123;&#125;"</span>.format(args.x, args.y, answer))</span><br></pre></td></tr></table></figure>

<p>æˆ‘ä»¬é€šè¿‡<code>group = parser.add_mutually_exclusive_group()</code>åˆ›å»ºäº†ä¸€ä¸ªäº’æ–¥ç»„ï¼Œç„¶åå°†ä¸¤ä¸ªå‚æ•°æ·»åŠ è¿›å»ï¼Œè¿™æ ·ï¼Œç”¨æˆ·å°±åªèƒ½é€‰æ‹©å…¶ä¸€æŒ‡å®šã€‚</p>
<p>ç»“æœï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python parse_test.py</span><br><span class="line">usage: parse_test.py [-h] [-v | -q] x y</span><br><span class="line">parse_test.py: error: the following arguments are required: x, y</span><br><span class="line">$ python parse_test.py 4 2</span><br><span class="line">4^2 == 16</span><br><span class="line">$ python parse_test.py 4 2 -å®‰</span><br><span class="line">16</span><br><span class="line">$ python parse_test.py 4 2 -ç</span><br><span class="line">4 to the power 2 equals 16</span><br></pre></td></tr></table></figure>

<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>äº‹å®ä¸Šï¼Œargparseræ¨¡å—æœ‰æ›´å¤šå¤æ‚æœ‰è¶£çš„åŠŸèƒ½ï¼Œå¯ä»¥åœ¨<a href="https://docs.python.org/3/library/argparse.html#module-argparse" target="_blank" rel="noopener"><code>å®˜æ–¹æ–‡æ¡£</code></a>ä¸­è¯¦ç»†äº†è§£ã€‚æœ¬æ–‡æ˜¯åœ¨<a href="https://docs.python.org/3/howto/argparse.html#id1" target="_blank" rel="noopener"><code>å®˜æ–¹æ•™ç¨‹</code></a>çš„åŸºç¡€ä¸Šæ”¹ç¼–è€Œæˆï¼Œå¦‚æœè§‰å¾—å†™çš„ä¸å¥½ï¼Œä¹Ÿè¯·ä¸è¦åœ¨ç½‘ç»œä¸Šé€¼é€¼èµ–èµ–ï¼Œæœ‰æœ¬äº‹ç°å®ç¢°ä¸€ç¢°ï¼Œä½ çœ‹æˆ‘æ‰ä¸æ‰ä½ å°±å®Œäº†ã€‚</p>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorchæ•™å­¦</title>
    <url>/2020/03/21/PyTorch%E6%95%99%E5%AD%A6/</url>
    <content><![CDATA[<h2 id="PyTorch-ä»‹ç»"><a href="#PyTorch-ä»‹ç»" class="headerlink" title="PyTorch ä»‹ç»"></a>PyTorch ä»‹ç»</h2><p>PyTorchæ˜¯ä¸€æ¬¾å¼ºæœ‰åŠ›çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¸ç®¡æ˜¯ç§‘ç ”è¿˜æ˜¯ç”Ÿäº§éƒ¨ç½²çš„éœ€æ±‚å®ƒéƒ½èƒ½æ»¡è¶³ã€‚<br>æœ¬æ•™ç¨‹ä»…æä¾›ç²—ç•¥çš„ä»‹ç»ï¼Œå¦‚æœæœ‰ä»»ä½•ç–‘é—®å¯ä»¥ä¸Šç½‘æŸ¥æŸ¥æˆ–æ˜¯å»å’¨è¯¢æœ‹å‹ã€‚ï¼ˆå°å£°bbï¼šå¤šgoogleå°‘ç™¾åº¦ï¼‰<br>ä¸€äº›ç”¨å¾—ä¸Šçš„pointï¼š</p>
<ul>
<li><p>è‡ªåŠ¨differentiationå·¥å…·éå¸¸å¼ºå¤§</p>
</li>
<li><p>PyTorchä¸ºä½ å®ç°å¥½äº†æ·±åº¦å­¦ä¹ ä¸­çš„å¸¸ç”¨åŠŸèƒ½</p>
</li>
<li><p>ä½¿ç”¨PyTorch DataSetæ¥å¤„ç†æ•°æ®</p>
</li>
</ul>
<h2 id="Tensorä¸numpyçš„å…³ç³»"><a href="#Tensorä¸numpyçš„å…³ç³»" class="headerlink" title="Tensorä¸numpyçš„å…³ç³»"></a>Tensorä¸numpyçš„å…³ç³»</h2><p>PyTorchçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œblockä¸numpyçš„ndarrayç›¸ä¼¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># we create tensors in a similar way to numpy nd arrays</span></span><br><span class="line">x_numpy = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line">x_torch = torch.tensor([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line">print(<span class="string">'x_numpy, x_torch'</span>)</span><br><span class="line">print(x_numpy, x_torch)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># to and from numpy, pytorch</span></span><br><span class="line">print(<span class="string">'to and from numpy and pytorch'</span>)</span><br><span class="line">print(torch.from_numpy(x_numpy), x_torch.numpy())</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># we can do basic operations like +-*/</span></span><br><span class="line">y_numpy = np.array([<span class="number">3</span>,<span class="number">4</span>,<span class="number">5.</span>])</span><br><span class="line">y_torch = torch.tensor([<span class="number">3</span>,<span class="number">4</span>,<span class="number">5.</span>])</span><br><span class="line">print(<span class="string">"x+y"</span>)</span><br><span class="line">print(x_numpy + y_numpy, x_torch + y_torch)</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># many functions that are in numpy are also in pytorch</span></span><br><span class="line">print(<span class="string">"norm"</span>)</span><br><span class="line">print(np.linalg.norm(x_numpy), torch.norm(x_torch))</span><br><span class="line">print()</span><br><span class="line"></span><br><span class="line"><span class="comment"># to apply an operation along a dimension,</span></span><br><span class="line"><span class="comment"># we use the dim keyword argument instead of axis</span></span><br><span class="line">print(<span class="string">"mean along the 0th dimension"</span>)</span><br><span class="line">x_numpy = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4.</span>]])</span><br><span class="line">x_torch = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4.</span>]])</span><br><span class="line">print(np.mean(x_numpy, axis=<span class="number">0</span>), torch.mean(x_torch, dim=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<h2 id="Tensor-view"><a href="#Tensor-view" class="headerlink" title="Tensor.view"></a>Tensor.view</h2><p>å’Œnumpy.reshape()ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨tensor.view()æ¥æ”¹å˜tensorçš„å½¢çŠ¶ã€‚å½“ä½¿ç”¨-1æ—¶ï¼Œå…¶è‡ªåŠ¨è®¡ç®—å‰©ä¸‹ç»´åº¦çš„å€¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># "MNIST"</span></span><br><span class="line">N, C, W, H = <span class="number">10000</span>, <span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span></span><br><span class="line">X = torch.randn((N, C, W, H))</span><br><span class="line"></span><br><span class="line">print(X.shape)</span><br><span class="line">print(X.view(N, C, <span class="number">784</span>).shape)</span><br><span class="line">print(X.view(<span class="number">-1</span>, C, <span class="number">784</span>).shape) <span class="comment"># automatically choose the 0th dimension</span></span><br></pre></td></tr></table></figure>
<h2 id="è®¡ç®—å›¾"><a href="#è®¡ç®—å›¾" class="headerlink" title="è®¡ç®—å›¾"></a>è®¡ç®—å›¾</h2><p>PyTorchçš„tensoræœ‰ä¸€ä¸ªç‰¹åˆ«çš„åœ°æ–¹ï¼Œå½“tensorå¯¹è±¡æ—¶ï¼ŒPytorchè‡ªåŠ¨åœ¨åå°åˆ›å»ºâ€œè®¡ç®—å›¾â€ã€‚è®¡ç®—å›¾æ˜¯ä½¿ç”¨å›¾çš„æ–¹å¼æ¥è¡¨è¾¾ä¸€ä¸ªæ•°å­¦è¡¨è¾¾å¼ã€‚å…¶å¸¦æœ‰ä¸€ç§ç®—æ³•æ¥è®¡ç®—ä¸€ä¸ªè®¡ç®—å›¾ä¸­æ‰€æœ‰å˜é‡çš„æ¢¯åº¦ï¼Œè®¡ç®—é¡ºåºå’Œå‡½æ•°æœ¬èº«çš„é¡ºåºä¸€è‡´ã€‚<br>å‡è®¾è¡¨è¾¾å¼ä¸º$e=(a+b)*(b+1)$,å…¶ä¸­ï¼Œ$a=2, b=1$æˆ‘ä»¬å¯ä»¥ç”»å‡ºå¦‚ä¸‹çš„è®¡ç®—å›¾ï¼š</p>
<p><img src="/" alt class="lazyload" data-src="/2020/03/21/PyTorch%E6%95%99%E5%AD%A6/tree-eval.png"></p>
<p>ä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.tensor(<span class="number">2.0</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># we set requires_grad=True to let PyTorch know to keep the graph</span></span><br><span class="line">b = torch.tensor(<span class="number">1.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">c = a + b</span><br><span class="line">d = b + <span class="number">1</span></span><br><span class="line">e = c * d</span><br><span class="line">print(<span class="string">'c'</span>, c)</span><br><span class="line">print(<span class="string">'d'</span>, d)</span><br><span class="line">print(<span class="string">'e'</span>, e)</span><br></pre></td></tr></table></figure>

<p>æ‰§è¡Œç»“æœä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;</span><br><span class="line">c tensor(<span class="number">3.</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">d tensor(<span class="number">2.</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">e tensor(<span class="number">6.</span>, grad_fn=&lt;MulBackward0&gt;)</span><br></pre></td></tr></table></figure>

<p>å¯ä»¥çœ‹åˆ°ï¼ŒPyTorchä¸ºæˆ‘ä»¬è®°å½•äº†è®¡ç®—å›¾ã€‚</p>
<h2 id="ä½¿ç”¨Pytorchæ¥è®¡ç®—æ¢¯åº¦"><a href="#ä½¿ç”¨Pytorchæ¥è®¡ç®—æ¢¯åº¦" class="headerlink" title="ä½¿ç”¨Pytorchæ¥è®¡ç®—æ¢¯åº¦"></a>ä½¿ç”¨Pytorchæ¥è®¡ç®—æ¢¯åº¦</h2><p>æˆ‘ä»¬å·²ç»å‘ç°PyTorchä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬è®°å½•è®¡ç®—å›¾ï¼Œç°åœ¨ï¼Œè®©æˆ‘ä»¬ç”¨å®ƒæ¥æ±‚ä¸€æ±‚æ¢¯åº¦ã€‚</p>
<p>è€ƒè™‘è¿™æ ·ä¸€ä¸ªæ–¹ç¨‹ï¼š$f(x)=(x-2)^2$ã€‚</p>
<p>é—®é¢˜ï¼šè®¡ç®—${df(x)}\over{dx}$ï¼Œæ±‚$fâ€™(1)$ã€‚</p>
<p>æˆ‘ä»¬å¯¹leaf variable <code>y</code>è°ƒç”¨<code>backward()</code>æ–¹æ³•ï¼Œä¸€æ¬¡æ€§è®¡ç®—<code>y</code>çš„æ‰€æœ‰æ¢¯åº¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (x<span class="number">-2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fp</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*(x<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = f(x)</span><br><span class="line">y.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Analytical f\'(x):'</span>, fp(x))</span><br><span class="line">print(<span class="string">'PyTorch\'s f\'(x):'</span>, x.grad)</span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;</span><br><span class="line">Analytical <span class="string">f'(x): tensor([-2.], grad_fn=&lt;MulBackward0&gt;) #å¸¦æœ‰grad_fn</span></span><br><span class="line"><span class="string">PyTorch'</span>s <span class="string">f'(x): tensor([-2.])</span></span><br></pre></td></tr></table></figure>

<p><code>backward()</code>ä¹Ÿå¯ä»¥è®¡ç®—å¸¦æœ‰æ•°å­¦å‡½æ•°çš„è¡¨è¾¾å¼çš„æ¢¯åº¦ï¼š</p>
<p>ç°æœ‰$w=[w_1,w_2]^T$ï¼Œ</p>
<p>$g(w)=2w_1w_2+w_2cos(w_1)$</p>
<p>é—®é¢˜ï¼šè®¡ç®—&nabla;$_w g(w)$ç„¶åéªŒè¯&nabla;$_w g([\pi,1]) = [2,\pi-1]^T$ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*w[<span class="number">0</span>]*w[<span class="number">1</span>] + w[<span class="number">1</span>]*torch.cos(w[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grad_g</span><span class="params">(w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor([<span class="number">2</span>*w[<span class="number">1</span>] - w[<span class="number">1</span>]*torch.sin(w[<span class="number">0</span>]), <span class="number">2</span>*w[<span class="number">0</span>] + torch.cos(w[<span class="number">0</span>])])</span><br><span class="line"></span><br><span class="line">w = torch.tensor([np.pi, <span class="number">1</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">z = g(w)</span><br><span class="line">z.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Analytical grad g(w)'</span>, grad_g(w))</span><br><span class="line">print(<span class="string">'PyTorch\'s grad g(w)'</span>, w.grad)</span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºå¦‚ä¸‹:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Analytical grad g(w) tensor([<span class="number">2.0000</span>, <span class="number">5.2832</span>])</span><br><span class="line">PyTorch<span class="string">'s grad g(w) tensor([2.0000, 5.2832])</span></span><br></pre></td></tr></table></figure>

<h2 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h2><p>æœ‰äº†æ¢¯åº¦ï¼Œå’±ä»¬å°±å¯ä»¥è¯•è¯•çœ‹æ¢¯åº¦ä¸‹é™ï¼š</p>
<p>å‡è®¾$f$å°±æ˜¯ä¸Šéƒ¨åˆ†å®šä¹‰çš„å‡½æ•°</p>
<p>é—®é¢˜ï¼šæ‰¾å‡ºä½¿å¾—$f$æœ€å°çš„$x$ã€‚</p>
<p>ä»£ç å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">step_size = <span class="number">0.25</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'iter,\tx,\tf(x),\tf\'(x),\tf\'(x) pytorch'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">15</span>):</span><br><span class="line">    y = f(x)</span><br><span class="line">    y.backward() <span class="comment"># compute the gradient</span></span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'&#123;&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;'</span>.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))</span><br><span class="line">    </span><br><span class="line">    x.data = x.data - step_size * x.grad <span class="comment"># perform a GD update step</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># We need to zero the grad variable since the backward()</span></span><br><span class="line">    <span class="comment"># call accumulates the gradients in .grad instead of overwriting.</span></span><br><span class="line">    <span class="comment"># The detach_() is for efficiency. You do not need to worry too much about it.</span></span><br><span class="line">    x.grad.detach_()</span><br><span class="line">    x.grad.zero_()</span><br></pre></td></tr></table></figure>

<p>ç»“æœä¸ºï¼š</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iter,	x,	f(x),	f<span class="string">'(x),	f'</span>(x) pytorch</span><br><span class="line">0,	5.000,	9.000,	6.000,	6.000</span><br><span class="line">1,	3.500,	2.250,	3.000,	3.000</span><br><span class="line">2,	2.750,	0.562,	1.500,	1.500</span><br><span class="line">3,	2.375,	0.141,	0.750,	0.750</span><br><span class="line">4,	2.188,	0.035,	0.375,	0.375</span><br><span class="line">5,	2.094,	0.009,	0.188,	0.188</span><br><span class="line">6,	2.047,	0.002,	0.094,	0.094</span><br><span class="line">7,	2.023,	0.001,	0.047,	0.047</span><br><span class="line">8,	2.012,	0.000,	0.023,	0.023</span><br><span class="line">9,	2.006,	0.000,	0.012,	0.012</span><br><span class="line">10,	2.003,	0.000,	0.006,	0.006</span><br><span class="line">11,	2.001,	0.000,	0.003,	0.003</span><br><span class="line">12,	2.001,	0.000,	0.001,	0.001</span><br><span class="line">13,	2.000,	0.000,	0.001,	0.001</span><br><span class="line">14,	2.000,	0.000,	0.000,	0.000</span><br></pre></td></tr></table></figure>

<h2 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h2><p>åˆšåˆšå’±ä»¬æœ€å°åŒ–äº†ä¸€ä¸ªçæ°å‡ºæ¥çš„å‡½æ•°ï¼Œç°åœ¨è®©æˆ‘ä»¬æœ€å°åŒ–ä¸€ä¸ªlosså‡½æ•°ï¼Œå¹¶æ”¾å…¥ä¸€äº›çæ°çš„dataã€‚</p>
<p>ç°åœ¨å’±ç”¨æ¢¯åº¦ä¸‹é™è§£å†³ä¸€ä¸‹çº¿æ€§å›å½’é—®é¢˜ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># make a simple linear dataset with some noise</span></span><br><span class="line"></span><br><span class="line">d = <span class="number">2</span></span><br><span class="line">n = <span class="number">50</span></span><br><span class="line">X = torch.randn(n,d)</span><br><span class="line">true_w = torch.tensor([[<span class="number">-1.0</span>], [<span class="number">2.0</span>]])</span><br><span class="line">y = X @ true_w + torch.randn(n,<span class="number">1</span>) * <span class="number">0.1</span> <span class="comment"># @æ˜¯çŸ©é˜µä¹˜æ³•ï¼Œ*æ˜¯å…ƒç´ é€ä¸ªç›¸ä¹˜ã€‚</span></span><br><span class="line">print(<span class="string">'X shape'</span>, X.shape)</span><br><span class="line">print(<span class="string">'y shape'</span>, y.shape)</span><br><span class="line">print(<span class="string">'w shape'</span>, true_w.shape)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X shape torch.Size([<span class="number">50</span>, <span class="number">2</span>])</span><br><span class="line">y shape torch.Size([<span class="number">50</span>, <span class="number">1</span>])</span><br><span class="line">w shape torch.Size([<span class="number">2</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<h2 id="éªŒè¯æ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§"><a href="#éªŒè¯æ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§" class="headerlink" title="éªŒè¯æ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§"></a>éªŒè¯æ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§</h2><p>æœ¬éƒ¨åˆ†æˆ‘ä»¬éªŒè¯PyTorchæ¢¯åº¦è®¡ç®—çš„æ­£ç¡®æ€§ã€‚</p>
<p>Lossçš„æ¢¯åº¦å…¬å¼å¦‚ä¸‹ï¼š</p>
<p>$\nabla _w \frac{1}{n}||y-Xw||_2^2=-\frac{2}{n}X^T(y-Xw)$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define a linear model with no bias</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X, w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> X @ w</span><br><span class="line"></span><br><span class="line"><span class="comment"># the residual sum of squares loss function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rss</span><span class="params">(y, y_hat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.norm(y - y_hat)**<span class="number">2</span> / n <span class="comment">#torch.normæ˜¯èŒƒæ•°</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># analytical expression for the gradient</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grad_rss</span><span class="params">(X, y, w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span>*X.t() @ (y - X @ w) / n</span><br><span class="line"></span><br><span class="line">w = torch.tensor([[<span class="number">1.</span>], [<span class="number">0</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y_hat = model(X, w)</span><br><span class="line"></span><br><span class="line">loss = rss(y, y_hat)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Analytical gradient'</span>, grad_rss(X, y, w).detach().view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'PyTorch\'s gradient'</span>, w.grad.view(<span class="number">2</span>).numpy())</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Analytical gradient [ <span class="number">3.974099</span> <span class="number">-4.494481</span>]</span><br><span class="line">PyTorch<span class="string">'s gradient [ 3.9740987 -4.4944816]</span></span><br></pre></td></tr></table></figure>

<p>ä»ç»“æœä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºPyTorchè®¡ç®—å‡ºäº†æ­£ç¡®çš„æ¢¯åº¦ï¼Œç°åœ¨è®©æˆ‘ä»¬æŠŠæ¢¯åº¦ç”¨èµ·æ¥å§ã€‚</p>
<h2 id="ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ŒåŸºäºè‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½çš„çº¿æ€§å›å½’"><a href="#ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ŒåŸºäºè‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½çš„çº¿æ€§å›å½’" class="headerlink" title="ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ŒåŸºäºè‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½çš„çº¿æ€§å›å½’"></a>ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ŒåŸºäºè‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½çš„çº¿æ€§å›å½’</h2><p>ç°åœ¨å’±ä»¬ç”¨å¾—å‡ºçš„æ¢¯åº¦æ¥å®ç°æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚</p>
<p>Note:è¿™ä¸ªä¾‹å­åªæ˜¯å•çº¯å±•ç¤ºå¦‚ä½•ç”¨PyTorchå°†ä¹‹å‰çš„æƒ³æ³•å®ç°å‡ºæ¥ï¼Œåé¢è¿˜ä¼šä»‹ç»å¦‚ä½•ç”¨PyTorchicçš„æ–¹å¼æ¥åšåŒæ ·çš„äº‹æƒ…ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">step_size = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'iter,\tloss,\tw'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    y_hat = model(X, w)</span><br><span class="line">    loss = rss(y, y_hat)</span><br><span class="line">    </span><br><span class="line">    loss.backward() <span class="comment"># compute the gradient of the loss</span></span><br><span class="line">    </span><br><span class="line">    w.data = w.data - step_size * w.grad <span class="comment"># do a gradient descent step</span></span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'&#123;&#125;,\t&#123;:.2f&#125;,\t&#123;&#125;'</span>.format(i, loss.item(), w.view(<span class="number">2</span>).detach().numpy()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># We need to zero the grad variable since the backward()</span></span><br><span class="line">    <span class="comment"># call accumulates the gradients in .grad instead of overwriting.</span></span><br><span class="line">    <span class="comment"># The detach_() is for efficiency. You do not need to worry too much about it.</span></span><br><span class="line">    w.grad.detach()</span><br><span class="line">    w.grad.zero_()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\ntrue w\t\t'</span>, true_w.view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'estimated w\t'</span>, w.view(<span class="number">2</span>).detach().numpy())</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iter,	loss,	w</span><br><span class="line"><span class="number">0</span>,	<span class="number">8.47</span>,	[<span class="number">0.20518023</span> <span class="number">0.89889634</span>]</span><br><span class="line"><span class="number">1</span>,	<span class="number">2.80</span>,	[<span class="number">-0.03049211</span>  <span class="number">1.1496693</span> ]</span><br><span class="line"><span class="number">2</span>,	<span class="number">1.75</span>,	[<span class="number">-0.21864393</span>  <span class="number">1.3446302</span> ]</span><br><span class="line"><span class="number">3</span>,	<span class="number">1.09</span>,	[<span class="number">-0.3690024</span>  <span class="number">1.4960643</span>]</span><br><span class="line"><span class="number">4</span>,	<span class="number">0.68</span>,	[<span class="number">-0.4892798</span>  <span class="number">1.6135726</span>]</span><br><span class="line"><span class="number">5</span>,	<span class="number">0.43</span>,	[<span class="number">-0.5855947</span>  <span class="number">1.7046558</span>]</span><br><span class="line"><span class="number">6</span>,	<span class="number">0.27</span>,	[<span class="number">-0.66280454</span>  <span class="number">1.7751708</span> ]</span><br><span class="line"><span class="number">7</span>,	<span class="number">0.18</span>,	[<span class="number">-0.7247683</span>  <span class="number">1.8296891</span>]</span><br><span class="line"><span class="number">8</span>,	<span class="number">0.11</span>,	[<span class="number">-0.7745538</span>  <span class="number">1.8717768</span>]</span><br><span class="line"><span class="number">9</span>,	<span class="number">0.08</span>,	[<span class="number">-0.8146021</span>  <span class="number">1.9042141</span>]</span><br><span class="line"><span class="number">10</span>,	<span class="number">0.05</span>,	[<span class="number">-0.84685683</span>  <span class="number">1.9291675</span> ]</span><br><span class="line"><span class="number">11</span>,	<span class="number">0.04</span>,	[<span class="number">-0.87286717</span>  <span class="number">1.9483235</span> ]</span><br><span class="line"><span class="number">12</span>,	<span class="number">0.03</span>,	[<span class="number">-0.89386874</span>  <span class="number">1.9629945</span> ]</span><br><span class="line"><span class="number">13</span>,	<span class="number">0.02</span>,	[<span class="number">-0.91084814</span>  <span class="number">1.9742005</span> ]</span><br><span class="line"><span class="number">14</span>,	<span class="number">0.02</span>,	[<span class="number">-0.9245938</span>  <span class="number">1.982734</span> ]</span><br><span class="line"><span class="number">15</span>,	<span class="number">0.02</span>,	[<span class="number">-0.93573654</span>  <span class="number">1.9892098</span> ]</span><br><span class="line"><span class="number">16</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9447814</span>  <span class="number">1.9941043</span>]</span><br><span class="line"><span class="number">17</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9521335</span>  <span class="number">1.9977864</span>]</span><br><span class="line"><span class="number">18</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9581177</span>  <span class="number">2.0005412</span>]</span><br><span class="line"><span class="number">19</span>,	<span class="number">0.01</span>,	[<span class="number">-0.96299535</span>  <span class="number">2.002589</span>  ]</span><br><span class="line"></span><br><span class="line">true w		 [<span class="number">-1.</span>  <span class="number">2.</span>]</span><br><span class="line">estimated w	 [<span class="number">-0.96299535</span>  <span class="number">2.002589</span>  ]</span><br></pre></td></tr></table></figure>

<h2 id="torch-nn-Module"><a href="#torch-nn-Module" class="headerlink" title="torch.nn.Module"></a>torch.nn.Module</h2><p><code>Module</code>æ˜¯PyTorchå¯¹tensoræ–½åŠ æ“ä½œçš„ä¸€ç§æ–¹å¼ï¼Œå„æ¨¡å—è¢«ä½œä¸ºtorch.nn.Moduleçš„å­ç±»å®ç°ã€‚æ‰€æœ‰æ¨¡å—éƒ½å¯ä»¥è¢«è°ƒç”¨ï¼Œå¹¶å¯ä»¥è¢«ç»„åˆèµ·æ¥å½¢æˆæ›´åŠ å¤æ‚çš„åŠŸèƒ½ã€‚</p>
<p><code>torch.nn</code><a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener">docs</a></p>
<p>Noteï¼šå¤šæ•°ä¸ºmoduleå®ç°çš„åŠŸèƒ½ä¹Ÿå¯ä»¥é€šè¿‡<code>torch.nn.functional</code>æ¥è®¿é—®ï¼Œä½†éœ€è¦ç”¨æˆ·è‡ªå·±ç»´æŠ¤æƒé‡tensorã€‚</p>
<p><code>torch.nn.functional</code><a href="https://pytorch.org/docs/stable/nn.html#torch-nn-functional" target="_blank" rel="noopener">docs</a></p>
<h2 id="Linear-Module"><a href="#Linear-Module" class="headerlink" title="Linear Module"></a>Linear Module</h2><p>Linear Moduleæ˜¯ä¸€ä¸ªå¸¸ç”¨æ¨¡å—ï¼Œå®ƒå¾ˆæ–¹ä¾¿åœ°å®ç°å¸¦æœ‰ä¸€ä¸ªbiasçš„çº¿æ€§å˜æ¢æ¨¡å‹ã€‚ä½ åªéœ€è¦æŒ‡å®šè¾“å…¥ç»“ç‚¹çš„ä¸ªæ•°ä¸è¾“å‡ºèŠ‚ç‚¹çš„ä¸ªæ•°ï¼Œå®ƒå°†è‡ªåŠ¨ä¸ºä½ ç”Ÿæˆä¸­é—´æƒé‡ä¸biasï¼Œåˆ›å»ºå‡ºç›¸åº”çš„çº¿æ€§æ¨¡å‹ã€‚</p>
<p>å’Œæˆ‘ä»¬æ‰‹åŠ¨åˆå§‹åŒ–$w$ä¸åŒçš„æ˜¯ï¼ŒLinear Moduleè‡ªåŠ¨ä¸ºæˆ‘ä»¬åˆå§‹åŒ–æƒé‡ã€‚å¯¹äºæœ€å°åŒ–ä¸€ä¸ªéå‡¸çš„losså‡½æ•°æ¥è¯´ï¼Œæƒé‡çš„åˆå§‹åŒ–æ˜¯éå¸¸é‡è¦çš„ã€‚å¦‚æœè®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æ²¡æœ‰æƒ³è±¡ä¸­çš„å¥½ï¼Œå¯ä»¥å°è¯•æ‰‹åŠ¨åˆå§‹åŒ–æƒé‡ï¼Œä½¿å…¶ä¸é»˜è®¤çš„æƒé‡ä¸åŒã€‚<code>torch.nn.init</code>ä¸­æœ‰ä¸€äº›å¸¸ç”¨çš„å‚æ•°åˆå§‹åŒ–æ–¹å¼ã€‚</p>
<p><code>torch.nn.init</code><a href="https://pytorch.org/docs/stable/nn.html#torch-nn-init" target="_blank" rel="noopener">docs</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d_in = <span class="number">3</span></span><br><span class="line">d_out = <span class="number">4</span></span><br><span class="line">linear_module = nn.Linear(d_in, d_out)</span><br><span class="line"></span><br><span class="line">example_tensor = torch.tensor([[<span class="number">1.</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># applys a linear transformation to the data</span></span><br><span class="line">transformed = linear_module(example_tensor)</span><br><span class="line">print(<span class="string">'example_tensor'</span>, example_tensor.shape)</span><br><span class="line">print(<span class="string">'transormed'</span>, transformed.shape)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'We can see that the weights exist in the background\n'</span>)</span><br><span class="line">print(<span class="string">'W:'</span>, linear_module.weight)</span><br><span class="line">print(<span class="string">'b:'</span>, linear_module.bias)</span><br></pre></td></tr></table></figure>



<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;</span><br><span class="line">print(<span class="string">'We can see that the weights exist in the background\n'</span>)</span><br><span class="line">print(<span class="string">'W:'</span>, linear_module.weight)</span><br><span class="line">print(<span class="string">'b:'</span>, linear_module.bias)</span><br><span class="line">example_tensor torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">transormed torch.Size([<span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">We can see that the weights exist <span class="keyword">in</span> the background</span><br><span class="line"></span><br><span class="line">W: Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.2383</span>, <span class="number">-0.0450</span>,  <span class="number">0.2986</span>],</span><br><span class="line">        [<span class="number">-0.0828</span>, <span class="number">-0.0900</span>,  <span class="number">0.2475</span>],</span><br><span class="line">        [<span class="number">-0.4174</span>,  <span class="number">0.3788</span>,  <span class="number">0.5005</span>],</span><br><span class="line">        [<span class="number">-0.3601</span>, <span class="number">-0.4104</span>, <span class="number">-0.0584</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">b: Parameter containing:</span><br><span class="line">tensor([<span class="number">-0.0385</span>, <span class="number">-0.0826</span>,  <span class="number">0.0033</span>,  <span class="number">0.4773</span>], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>å¯ä»¥çœ‹åˆ°ï¼Œå’±ä»¬åªæ˜¯æŒ‡å®šäº†è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ï¼ŒLinear Moduleå°±æ›¿æˆ‘ä»¬æŠŠweightå’Œbiaså…¨åˆ›å»ºå¥½äº†ã€‚</p>
<h2 id="æ¿€æ´»å‡½æ•°"><a href="#æ¿€æ´»å‡½æ•°" class="headerlink" title="æ¿€æ´»å‡½æ•°"></a>æ¿€æ´»å‡½æ•°</h2><p>PyTorché‡Œå¤´é¢„å…ˆå®ç°äº†ä¸€å¤§ç¥¨çš„æ¿€æ´»å‡½æ•°ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºReLUã€Tanhå’ŒSigmoidã€‚å› ä¸ºä»–ä»¬éƒ½æ˜¯æ¨¡å—ï¼Œæ‰€ä»¥ä½¿ç”¨æ—¶éœ€è¦å…ˆå®ä¾‹åŒ–ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">activation_fn = nn.ReLU() <span class="comment"># we instantiate an instance of the ReLU module</span></span><br><span class="line">example_tensor = torch.tensor([<span class="number">-1.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br><span class="line">activated = activation_fn(example_tensor)</span><br><span class="line">print(<span class="string">'example_tensor'</span>, example_tensor)</span><br><span class="line">print(<span class="string">'activated'</span>, activated)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">example_tensor tensor([<span class="number">-1.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>])</span><br><span class="line">activated tensor([<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>])</span><br></pre></td></tr></table></figure>

<h2 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h2><p>Sequentialæä¾›ç»™å’±ä»¬ä¸€ä¸ªç»ä½³çš„è§£å†³æ–¹æ¡ˆï¼Œç”¨äºå°†å¤šä¸ªç®€å•æ¨¡å—ç»„åˆåœ¨ä¸€èµ·ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d_in = <span class="number">3</span></span><br><span class="line">d_hidden = <span class="number">4</span></span><br><span class="line">d_out = <span class="number">1</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">                            nn.Linear(d_in, d_hidden),</span><br><span class="line">                            nn.Tanh(),</span><br><span class="line">                            nn.Linear(d_hidden, d_out),</span><br><span class="line">                            nn.Sigmoid()</span><br><span class="line">                           )</span><br><span class="line"></span><br><span class="line">example_tensor = torch.tensor([[<span class="number">1.</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">transformed = model(example_tensor)</span><br><span class="line">print(<span class="string">'transformed'</span>, transformed.shape)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;</span><br><span class="line">transformed torch.Size([<span class="number">2</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>å°æŠ€å·§ï¼šå’±ä»¬å¯ä»¥ä½¿ç”¨<code>parameters()</code>æ–¹æ³•æ¥å¾—åˆ°å¾—åˆ°ä»»ä½•<code>nn.Module( )</code>çš„å‚æ•°ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = model.parameters()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    print(param)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Parameter containing:</span><br><span class="line">tensor([[<span class="number">-0.5554</span>,  <span class="number">0.0456</span>, <span class="number">-0.3115</span>],</span><br><span class="line">        [ <span class="number">0.0697</span>, <span class="number">-0.1629</span>,  <span class="number">0.3342</span>],</span><br><span class="line">        [ <span class="number">0.1340</span>, <span class="number">-0.1353</span>,  <span class="number">0.1261</span>],</span><br><span class="line">        [ <span class="number">0.0624</span>,  <span class="number">0.3285</span>, <span class="number">-0.4536</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.3684</span>, <span class="number">-0.0760</span>, <span class="number">-0.2277</span>, <span class="number">-0.0276</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">0.0345</span>, <span class="number">-0.0294</span>, <span class="number">-0.1481</span>,  <span class="number">0.4977</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.1952</span>], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>PyTorchä¸­ä¸ºæˆ‘ä»¬é¢„å…ˆå®ç°å¥½äº†å¾ˆå¤šlosså‡½æ•°ï¼Œæ¯”æ–¹è¯´<code>MSELoss</code>å’Œ<code>CrossEntropyLoss</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mse_loss_fn = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">input = torch.tensor([[<span class="number">0.</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1.</span>, <span class="number">0</span>, <span class="number">-1</span>]])</span><br><span class="line"></span><br><span class="line">loss = mse_loss_fn(input, target)</span><br><span class="line"></span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor(<span class="number">0.6667</span>)</span><br></pre></td></tr></table></figure>

<h2 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h2><p>PyTorchå®ç°äº†å¾ˆå¤šä¼˜åŒ–æ–¹æ³•ã€‚åœ¨ä½¿ç”¨æ—¶ï¼Œä½ æœ€å°‘ä¹Ÿè¦æŒ‡å®šæ¨¡å‹å‚æ•°å’Œå­¦ä¹ ç‡ã€‚</p>
<p>ä¼˜åŒ–å™¨è™½å¥½ï¼Œä½†å®ƒå¹¶ä¸ä¼šè‡ªåŠ¨å¸®ä½ è®¡ç®—æ¢¯åº¦ã€‚soï¼Œä½ è‡ªå·±è¦è®°å¾—è°ƒç”¨ä¸€ä¸‹<code>backward()</code>å¥¥å¯¹äº†ï¼Œåœ¨è¿è¡Œè¿™ä¸ªä¹‹å‰è¿˜è¦è®°å¾—è°ƒç”¨ä¸€ä¸‹<code>optim.zero_grad()&#39;åˆå§‹åŒ–ä¸€ä¸‹.gradé‡Œå¤´çš„å˜é‡ã€‚è¿™ç›¸å½“äºå¯¹æ‰€æœ‰.gradé‡Œå¤´çš„å˜é‡åš</code>detach_()<code>å’Œ</code>zero_()`</p>
<p><code>torch.optim</code><a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener">docs</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create a simple model</span></span><br><span class="line">model = nn.Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a simple dataset</span></span><br><span class="line">X_simple = torch.tensor([[<span class="number">1.</span>]])</span><br><span class="line">y_simple = torch.tensor([[<span class="number">2.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># create our optimizer</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line">mse_loss_fn = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">y_hat = model(X_simple)</span><br><span class="line">print(<span class="string">'model params before:'</span>, model.weight)</span><br><span class="line">loss = mse_loss_fn(y_hat, y_simple)</span><br><span class="line">optim.zero_grad()</span><br><span class="line">loss.backward()</span><br><span class="line">optim.step()</span><br><span class="line">print(<span class="string">'model params after:'</span>, model.weight)</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model params before: Parameter containing:</span><br><span class="line">tensor([[<span class="number">0.7107</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">model params after: Parameter containing:</span><br><span class="line">tensor([[<span class="number">0.7547</span>]], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>å¯ä»¥çœ‹åˆ°ï¼Œå‚æ•°å‘æ­£ç¡®çš„æ–¹å‘å˜åŒ–ã€‚</p>
<h2 id="ç”¨æ¢¯åº¦ä¸‹é™ã€è‡ªåŠ¨æ±‚å¯¼ä¸PyTorchæ¨¡å—å®ç°çº¿æ€§å›å½’"><a href="#ç”¨æ¢¯åº¦ä¸‹é™ã€è‡ªåŠ¨æ±‚å¯¼ä¸PyTorchæ¨¡å—å®ç°çº¿æ€§å›å½’" class="headerlink" title="ç”¨æ¢¯åº¦ä¸‹é™ã€è‡ªåŠ¨æ±‚å¯¼ä¸PyTorchæ¨¡å—å®ç°çº¿æ€§å›å½’"></a>ç”¨æ¢¯åº¦ä¸‹é™ã€è‡ªåŠ¨æ±‚å¯¼ä¸PyTorchæ¨¡å—å®ç°çº¿æ€§å›å½’</h2><p>ç°åœ¨ï¼Œå’±ä»¬æŠŠå‰é¢å­¦çš„ä¸€å †ä¸œè¥¿æ‰åœ¨ä¸€èµ·ï¼Œç”¨PyTorchicçš„æ–¹å¼å®ç°çº¿æ€§å›å½’ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">step_size = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">linear_module = nn.Linear(d, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'iter,\tloss,\tw'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    y_hat = linear_module(X)</span><br><span class="line">    loss = loss_func(y_hat, y)</span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optim.step()</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'&#123;&#125;,\t&#123;:.2f&#125;,\t&#123;&#125;'</span>.format(i, loss.item(), linear_module.weight.view(<span class="number">2</span>).detach().numpy()))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\ntrue w\t\t'</span>, true_w.view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'estimated w\t'</span>, linear_module.weight.view(<span class="number">2</span>).detach().numpy())</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iter,	loss,	w</span><br><span class="line"><span class="number">0</span>,	<span class="number">3.38</span>,	[<span class="number">-0.06555872</span>  <span class="number">0.9564365</span> ]</span><br><span class="line"><span class="number">1</span>,	<span class="number">2.09</span>,	[<span class="number">-0.25302264</span>  <span class="number">1.1884048</span> ]</span><br><span class="line"><span class="number">2</span>,	<span class="number">1.30</span>,	[<span class="number">-0.40178707</span>  <span class="number">1.3695917</span> ]</span><br><span class="line"><span class="number">3</span>,	<span class="number">0.81</span>,	[<span class="number">-0.5199211</span>  <span class="number">1.5110494</span>]</span><br><span class="line"><span class="number">4</span>,	<span class="number">0.50</span>,	[<span class="number">-0.61379874</span>  <span class="number">1.6214342</span> ]</span><br><span class="line"><span class="number">5</span>,	<span class="number">0.32</span>,	[<span class="number">-0.68845654</span>  <span class="number">1.7075248</span> ]</span><br><span class="line"><span class="number">6</span>,	<span class="number">0.20</span>,	[<span class="number">-0.74787635</span>  <span class="number">1.774628</span>  ]</span><br><span class="line"><span class="number">7</span>,	<span class="number">0.13</span>,	[<span class="number">-0.79520756</span>  <span class="number">1.8268977</span> ]</span><br><span class="line"><span class="number">8</span>,	<span class="number">0.08</span>,	[<span class="number">-0.83294225</span>  <span class="number">1.8675839</span> ]</span><br><span class="line"><span class="number">9</span>,	<span class="number">0.06</span>,	[<span class="number">-0.8630534</span>  <span class="number">1.8992288</span>]</span><br><span class="line"><span class="number">10</span>,	<span class="number">0.04</span>,	[<span class="number">-0.8871039</span>  <span class="number">1.9238206</span>]</span><br><span class="line"><span class="number">11</span>,	<span class="number">0.03</span>,	[<span class="number">-0.9063326</span>  <span class="number">1.9429132</span>]</span><br><span class="line"><span class="number">12</span>,	<span class="number">0.02</span>,	[<span class="number">-0.921722</span>   <span class="number">1.9577209</span>]</span><br><span class="line"><span class="number">13</span>,	<span class="number">0.02</span>,	[<span class="number">-0.9340517</span>  <span class="number">1.9691923</span>]</span><br><span class="line"><span class="number">14</span>,	<span class="number">0.02</span>,	[<span class="number">-0.9439409</span>  <span class="number">1.9780676</span>]</span><br><span class="line"><span class="number">15</span>,	<span class="number">0.01</span>,	[<span class="number">-0.95188165</span>  <span class="number">1.9849249</span> ]</span><br><span class="line"><span class="number">16</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9582653</span>  <span class="number">1.9902146</span>]</span><br><span class="line"><span class="number">17</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9634034</span>  <span class="number">1.9942878</span>]</span><br><span class="line"><span class="number">18</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9675441</span>  <span class="number">1.9974183</span>]</span><br><span class="line"><span class="number">19</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9708851</span>  <span class="number">1.9998189</span>]</span><br><span class="line"></span><br><span class="line">true w		 [<span class="number">-1.</span>  <span class="number">2.</span>]</span><br><span class="line">estimated w	 [<span class="number">-0.9708851</span>  <span class="number">1.9998189</span>]</span><br></pre></td></tr></table></figure>

<h2 id="ä½¿ç”¨SGDå®Œæˆçº¿æ€§å›å½’"><a href="#ä½¿ç”¨SGDå®Œæˆçº¿æ€§å›å½’" class="headerlink" title="ä½¿ç”¨SGDå®Œæˆçº¿æ€§å›å½’"></a>ä½¿ç”¨SGDå®Œæˆçº¿æ€§å›å½’</h2><p>åœ¨ä¸Šä¸€ä¸ªä¾‹å­ä¸­ï¼Œå’±ä»¬è®¡ç®—åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šçš„å¹³å‡æ¢¯åº¦(Gradient Decent)ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•ä¿®æ”¹å®ç°éšæœºæ¢¯åº¦ä¸‹é™(Stochastic Gradient Descent)ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">step_size = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">linear_module = nn.Linear(d, <span class="number">1</span>)</span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line">optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)</span><br><span class="line">print(<span class="string">'iter,\tloss,\tw'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">    rand_idx = np.random.choice(n) <span class="comment"># take a random point from the dataset</span></span><br><span class="line">    x = X[rand_idx] </span><br><span class="line">    y_hat = linear_module(x)</span><br><span class="line">    loss = loss_func(y_hat, y[rand_idx]) <span class="comment"># only compute the loss on the single point</span></span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optim.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'&#123;&#125;,\t&#123;:.2f&#125;,\t&#123;&#125;'</span>.format(i, loss.item(), linear_module.weight.view(<span class="number">2</span>).detach().numpy()))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\ntrue w\t\t'</span>, true_w.view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'estimated w\t'</span>, linear_module.weight.view(<span class="number">2</span>).detach().numpy())</span><br></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iter,	loss,	w</span><br><span class="line"><span class="number">0</span>,	<span class="number">17.04</span>,	[ <span class="number">0.5124521</span>  <span class="number">-0.06253883</span>]</span><br><span class="line"><span class="number">20</span>,	<span class="number">0.52</span>,	[<span class="number">0.05047676</span> <span class="number">0.4122801</span> ]</span><br><span class="line"><span class="number">40</span>,	<span class="number">0.10</span>,	[<span class="number">-0.29989475</span>  <span class="number">0.9859146</span> ]</span><br><span class="line"><span class="number">60</span>,	<span class="number">2.08</span>,	[<span class="number">-0.65285033</span>  <span class="number">1.3815426</span> ]</span><br><span class="line"><span class="number">80</span>,	<span class="number">0.07</span>,	[<span class="number">-0.787713</span>   <span class="number">1.4951732</span>]</span><br><span class="line"><span class="number">100</span>,	<span class="number">0.28</span>,	[<span class="number">-0.90760225</span>  <span class="number">1.683282</span>  ]</span><br><span class="line"><span class="number">120</span>,	<span class="number">0.01</span>,	[<span class="number">-0.92447585</span>  <span class="number">1.8040558</span> ]</span><br><span class="line"><span class="number">140</span>,	<span class="number">0.00</span>,	[<span class="number">-0.9492291</span>  <span class="number">1.8816731</span>]</span><br><span class="line"><span class="number">160</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9679263</span>  <span class="number">1.9195584</span>]</span><br><span class="line"><span class="number">180</span>,	<span class="number">0.01</span>,	[<span class="number">-0.9705014</span>  <span class="number">1.9513198</span>]</span><br><span class="line"></span><br><span class="line">true w		 [<span class="number">-1.</span>  <span class="number">2.</span>]</span><br><span class="line">estimated w	 [<span class="number">-0.9696742</span>  <span class="number">1.9616756</span>]</span><br></pre></td></tr></table></figure>

<p>å…¶ä¸­ï¼Œå’±ä»¬é€šè¿‡<code>np.random.choice(n)</code>éšæœºé€‰å–ä¸€ä¸ªæ•°æ®ç”¨ä»¥æ›´æ–°è€Œä¸æ˜¯åŸºäºæ•´ä¸ªæ•°æ®é›†æ›´æ–°ã€‚ï¼ˆè¿™è¾¹ç›¸å½“äºæ˜¯é’ˆå¯¹dataçš„stachasticï¼‰ã€‚</p>
<h2 id="CrossEntropyLoss"><a href="#CrossEntropyLoss" class="headerlink" title="CrossEntropyLoss"></a>CrossEntropyLoss</h2><p>ç°åœ¨ï¼Œå’±ä»¬ç”¨CrossEntropyä½œä¸ºlosså‡½æ•°æ¥è¿›è¡Œä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚</p>
<p>PyTorchåœ¨<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss" target="_blank" rel="noopener">CrossEntropyLoss</a>æ¨¡å—ä¸­é¢„å…ˆå®ç°äº†ä¸€ä¸ªç‰ˆæœ¬çš„cross entropyï¼Œå®ƒçš„ç”¨æ³•å’ŒMSEç¨å¾®æœ‰ç‚¹ä¸åŒï¼Œæ‰€ä»¥è¿™å„¿è¯¦ç»†çé€¼é€¼ä¸€ä¸‹å®ƒçš„å‚æ•°ï¼š</p>
<ul>
<li><p>input:ç¬¬ä¸€ä¸ªå‚æ•°å°±æ˜¯å’±ä»¬çš„åˆ†ç±»ç¥ç»ç½‘ç»œçš„åŸå§‹è¾“å‡ºï¼Œå®ƒåº”è¯¥æ˜¯ä¸€ä¸ªç»´åº¦ä¸º(N, C)çš„å¼ é‡ã€‚å…¶ä¸­ï¼ŒNæ˜¯minibatchçš„å¤§å°ï¼Œè€ŒCæ˜¯classçš„æ•°é‡ã€‚å…¶ä¸­ï¼Œç¬¬äºŒç»´çš„æ•°æ®æ˜¯å½“å‰è¾“å…¥è¢«åˆ†åˆ°å„ç±»åˆ«çš„æ²¡æœ‰normalizeè¿‡çš„åŸå§‹æ‰“åˆ†ã€‚CrossEntropyLossæ¨¡å—è‡ªåŠ¨ä¸ºæˆ‘ä»¬è®¡ç®—softmaxï¼Œå› æ­¤æˆ‘ä»¬ä¸éœ€è¦è‡ªå·±ç®—ã€‚</p>
</li>
<li><p>output:ç¬¬äºŒä¸ªå‚æ•°æ˜¯æ•°æ®å¯¹åº”çš„labelï¼Œç”¨çš„æ—¶å€™åº”è¯¥è¾“å…¥ä¸€ä¸ªé•¿åº¦ä¸ºNçš„å¼ é‡ã€‚æ¯ä¸ªç»´åº¦ä¸Šæ˜¯æ­£ç¡®çš„ç±»åˆ«ã€‚</p>
</li>
</ul>
<p>ä¸‹æ–¹ä»£ç å±•ç¤ºä¸‰ä¸ªé¢„æµ‹åœ¨CrossEntropyLossä¸Šçš„æ‰“åˆ†ã€‚æ­£ç¡®çš„labelä¸º$y=[1, 1, 0]$ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">input = torch.tensor([[<span class="number">-1.</span>, <span class="number">1</span>],[<span class="number">-1</span>, <span class="number">1</span>],[<span class="number">1</span>, <span class="number">-1</span>]]) <span class="comment"># raw scores correspond to the correct class</span></span><br><span class="line"><span class="comment"># input = torch.tensor([[-3., 3],[-3, 3],[3, -3]]) # raw scores correspond to the correct class with higher confidence</span></span><br><span class="line"><span class="comment"># input = torch.tensor([[1., -1],[1, -1],[-1, 1]]) # raw scores correspond to the incorrect class</span></span><br><span class="line"><span class="comment"># input = torch.tensor([[3., -3],[3, -3],[-3, 3]]) # raw scores correspond to the incorrect class with incorrectly placed confidence</span></span><br><span class="line"></span><br><span class="line">target = torch.tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">output = loss(input, target)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>



<p>è¾“å‡º:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;</span><br><span class="line">tensor(<span class="number">0.1269</span>)</span><br></pre></td></tr></table></figure>

<h2 id="åŠ¨æ€æ”¹å˜å­¦ä¹ é€Ÿç‡"><a href="#åŠ¨æ€æ”¹å˜å­¦ä¹ é€Ÿç‡" class="headerlink" title="åŠ¨æ€æ”¹å˜å­¦ä¹ é€Ÿç‡"></a>åŠ¨æ€æ”¹å˜å­¦ä¹ é€Ÿç‡</h2><p>é€šå¸¸ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å…¨ç¨‹é‡‡ç”¨ç›¸åŒçš„å­¦ä¹ é€Ÿç‡ã€‚PyTorchæä¾›ç›¸åº”ç»„ä»¶æ”¯æŒæ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒæ•´å­¦ä¹ é€Ÿç‡ã€‚é€šå¸¸çš„ç­–ç•¥åŒ…æ‹¬æ¯ä¸ªepochå¯¹å­¦ä¹ é€Ÿç‡lrä¹˜ä»¥ä¸€ä¸ªæ¯”ç‡ï¼ˆæ¯”å¦‚0.9ï¼‰ï¼Œå¹¶åœ¨è®­ç»ƒlossä¸‹é™åœ°æ²¡é‚£ä¹ˆå¿«æ—¶å°†å­¦ä¹ é€Ÿç‡å‡åŠã€‚</p>
<p>æŸ¥çœ‹<a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" target="_blank" rel="noopener">learning rate scheduler docs</a>è·å–æ›´å¤šä¿¡æ¯ã€‚</p>
<h2 id="å·ç§¯"><a href="#å·ç§¯" class="headerlink" title="å·ç§¯"></a>å·ç§¯</h2><p>å½“æ•°æ®æ˜¯å›¾ç‰‡æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›ä½¿ç”¨å·ç§¯æ“ä½œæ¥æ€¼å®ƒã€‚PyTorhåœ¨<code>torch.nn.Conv2d</code>æ¨¡å—ä¸­å®ç°äº†å·ç§¯æ“ä½œã€‚ç”¨æˆ·éœ€è¦ä¼ å…¥ä¸€ä¸ª$(N,C_{in},H_{in},W_{in})$ã€‚å…¶ä¸­ï¼Œ$N$æ˜¯batchå¤§å°ï¼Œ$C_{in}$æ˜¯é€šé“æ•°ï¼Œ$H_{in}$å’Œ$W_{in}$åˆ†åˆ«æ˜¯è¾“å…¥å›¾ç‰‡çš„é«˜å’Œå®½ã€‚</p>
<p>é€šè¿‡è‡ªå®šä¹‰ä»¥ä¸‹å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä¿®æ”¹å·ç§¯æ“ä½œï¼š</p>
<ul>
<li>å·ç§¯æ ¸å¤§å°</li>
<li>æ­¥é•¿</li>
<li>å¡«å……</li>
</ul>
<p>è¿™äº›å‚æ•°å¯¹è¾“å‡ºå¼ é‡çš„ç»´åº¦æœ‰å½±å“ï¼Œæ‰€ä»¥åº”è¯¥å°å¿ƒã€‚</p>
<p>åœ¨<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d" target="_blank" rel="noopener"><code>torch.nn.Conv2d</code> docs</a>ä¸­æŸ¥çœ‹æ›´å¤šä¿¡æ¯ã€‚</p>
<p>æ —å­ï¼š</p>
<p>åœ¨å›¾ç‰‡ä¸Šæ€¼ä¸€ä¸ªgaussian blur kernelï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># a gaussian blur kernel</span></span><br><span class="line">gaussian_kernel = torch.tensor([[<span class="number">1.</span>, <span class="number">2</span>, <span class="number">1</span>],[<span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>],[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]]) / <span class="number">16.0</span></span><br><span class="line"></span><br><span class="line">conv = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># manually set the conv weight</span></span><br><span class="line">conv.weight.data[:] = gaussian_kernel</span><br><span class="line"></span><br><span class="line">convolved = conv(image_torch)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'original image'</span>)</span><br><span class="line">plt.imshow(image_torch.view(<span class="number">28</span>,<span class="number">28</span>).detach().numpy())</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'blurred image'</span>)</span><br><span class="line">plt.imshow(convolved.view(<span class="number">26</span>,<span class="number">26</span>).detach().numpy())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>è¯»å–ä¸€å¼ RGBå›¾ç‰‡ï¼Œè¾“å…¥é€šé“æ•°ä¸º3ï¼Œè¾“å‡ºé€šé“æ•°ä¸º16ï¼Œåœ¨ç»è¿‡ä¸€ä¸ªæ¿€æ´»å‡½æ•°å¤„ç†åï¼Œä»£ç éƒ¨åˆ†å±•ç¤ºçš„è¾“å‡ºç»“æœåˆå¯ä»¥ä½œä¸ºä¸€ä¸ª<code>Conv2d</code>çš„è¾“å…¥ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im_channels = <span class="number">3</span> <span class="comment"># if we are working with RGB images, there are 3 input channels, with black and white, 1</span></span><br><span class="line">out_channels = <span class="number">16</span> <span class="comment"># this is a hyperparameter we can tune</span></span><br><span class="line">kernel_size = <span class="number">3</span> <span class="comment"># this is another hyperparameter we can tune</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">image_width = <span class="number">32</span></span><br><span class="line">image_height = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">im = torch.randn(batch_size, im_channels, image_width, image_height)</span><br><span class="line"></span><br><span class="line">m = nn.Conv2d(im_channels, out_channels, kernel_size)</span><br><span class="line">convolved = m(im) <span class="comment"># it is a module so we can call it</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'im shape'</span>, im.shape)</span><br><span class="line">print(<span class="string">'convolved im shape'</span>, convolved.shape)</span><br></pre></td></tr></table></figure>

<h2 id="ä¸€äº›è›®æœ‰ç”¨çš„é“¾æ¥"><a href="#ä¸€äº›è›®æœ‰ç”¨çš„é“¾æ¥" class="headerlink" title="ä¸€äº›è›®æœ‰ç”¨çš„é“¾æ¥"></a>ä¸€äº›è›®æœ‰ç”¨çš„é“¾æ¥</h2><ul>
<li><p><a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" target="_blank" rel="noopener">60 minute PyTorch Tutorial</a></p>
</li>
<li><p><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">PyTorch Docs</a></p>
</li>
<li><p><a href="https://courses.cs.washington.edu/courses/cse446/19wi/notes/auto-diff.pdf" target="_blank" rel="noopener">Lecture notes on Auto-Diff</a></p>
</li>
</ul>
<h2 id="æ•°æ®ç±»"><a href="#æ•°æ®ç±»" class="headerlink" title="æ•°æ®ç±»"></a>æ•°æ®ç±»</h2><p><code>torch.utils.data.Dataset</code>æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œå’±ä»¬å¦‚æœè¦å¼„ä¸€ä¸ªè‡ªå·±çš„æ•°æ®é›†çš„è¯å°±éœ€è¦ç»§æ‰¿<code>Dataset</code>ï¼Œç„¶åè¦†ç›–ä»¥ä¸‹çš„æ–¹æ³•ï¼š</p>
<ul>
<li><code>__len__</code>ï¼Œç¡®ä¿<code>len(dataset)</code>å¯ä»¥æ­£ç¡®è¿”å›æ•°æ®é›†çš„å¤§å°ã€‚</li>
<li><code>__getitem__</code>ç”¨æ¥å®ç°ç´¢å¼•ï¼Œç¡®ä¿dataset[i]å¯ä»¥æ­£ç¡®æ‹¿åˆ°ç¬¬iä¸ªæ•°æ®ã€‚</li>
</ul>
<p>å’±ä»¬ç°åœ¨æ¥æä¸€ä¸ªface landmarksæ•°æ®é›†ã€‚å’±ä»¬åœ¨<code>__init__</code>é‡Œå¤´è¯»å–csvæ–‡ä»¶ï¼Œä½†æŠŠè¯»å–å›¾ç‰‡çš„ä»»åŠ¡ç•™ç»™<code>__getitem__</code>ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯èŠ‚çœå†…å­˜ï¼Œä¸éœ€è¦å°†æ‰€æœ‰æ•°æ®ä¸€ä¸‹å­å…¨è¯»åˆ°å†…å­˜é‡Œå»ã€‚</p>
<p>å’±ä»¬æ•°æ®é›†çš„sampleæ˜¯ä¸€ä¸ªdict:<code>{&#39;image&#39;: image, &#39;landmarks&#39;: landmarks}</code>ã€‚å’±ä»¬æ•°æ®é›†è¿˜è¦å†å¼„ä¸€ä¸ª<code>transform</code>æ–¹æ³•ï¼Œè¿™æ ·ä»»ä½•éœ€è¦çš„æ“ä½œéƒ½å¯ä»¥è¢«æ–½åŠ åœ¨å›¾ç‰‡ä¸Šã€‚å’±ä»¬åœ¨ä¸‹ä¸€èŠ‚é‡Œå¤´çœ‹çœ‹å®ƒçš„ç”¨å¤„ã€‚</p>
<p>æ —å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FaceLandmarksDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="string">"""Face Landmarks dataset."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, csv_file, root_dir, transform=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            csv_file (string): Path to the csv file with annotations.</span></span><br><span class="line"><span class="string">            root_dir (string): Directory with all the images.</span></span><br><span class="line"><span class="string">            transform (callable, optional): Optional transform to be applied</span></span><br><span class="line"><span class="string">                on a sample.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.landmarks_frame)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line"></span><br><span class="line">        img_name = os.path.join(self.root_dir,</span><br><span class="line">                                self.landmarks_frame.iloc[idx, <span class="number">0</span>])</span><br><span class="line">        image = io.imread(img_name)</span><br><span class="line">        landmarks = self.landmarks_frame.iloc[idx, <span class="number">1</span>:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(<span class="string">'float'</span>).reshape(<span class="number">-1</span>, <span class="number">2</span>)</span><br><span class="line">        sample = &#123;<span class="string">'image'</span>: image, <span class="string">'landmarks'</span>: landmarks&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample</span><br></pre></td></tr></table></figure>

<p>ç„¶é¹…ï¼Œå¦‚æœå’±ä»¬ç›´æ¥ç”¨<code>for</code>æŠŠæ•´ä¸ªæ•°æ®èµ°ä¸€éä¼šå°‘æ‰å¾ˆå¤šä¸œè¥¿ï¼Œæ¯”å¦‚:</p>
<ul>
<li>æŒ‰batchè¯»å–data</li>
<li>éšæœºè¯»å–data</li>
<li>å¤šçº¿ç¨‹è¯»å–data</li>
</ul>
<p>ä¸è¿‡æ–½ä¸»å…ˆä¸è¦ç€æ€¥ï¼Œè¿™äº›åŠŸèƒ½<code>torch.utils.data.DataLoader</code>éƒ½æœ‰ã€‚é€šè¿‡ä¿®æ”¹<code>collate_fn</code>å‚æ•°ï¼Œä½ å¯ä»¥æŒ‡å®šæ•°æ®æŒ‰ä»€ä¹ˆæ ·çš„batchæ–¹å¼è¢«è¯»å–ï¼Œä¸è¿‡é»˜è®¤çš„è¯»å–æ–¹æ³•å·²ç»å¯ä»¥coverå¤§éƒ¨åˆ†çš„éœ€æ±‚äº†ã€‚</p>
<p>ğŸŒ°ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataloader = DataLoader(transformed_dataset, batch_size=<span class="number">4</span>,</span><br><span class="line">                        shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i_batch, sample_batched <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">    print(i_batch, sample_batched[<span class="string">'image'</span>].size(),</span><br><span class="line">          sample_batched[<span class="string">'landmarks'</span>].size())</span><br></pre></td></tr></table></figure>

<h2 id="æ··åˆç²¾åº¦è®­ç»ƒ"><a href="#æ··åˆç²¾åº¦è®­ç»ƒ" class="headerlink" title="æ··åˆç²¾åº¦è®­ç»ƒ"></a>æ··åˆç²¾åº¦è®­ç»ƒ</h2><p>ä½œè€…: <code>Chi-Liang Liu</code> å¼•ç”¨: <a href="https://github.com/NVIDIA/apexã€‚é‡‡ç”¨æ··åˆç²¾åº¦è®­ç»ƒä½ çš„æ¨¡å‹ï¼Œè®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå¯ä»¥ï¼š" target="_blank" rel="noopener">https://github.com/NVIDIA/apexã€‚é‡‡ç”¨æ··åˆç²¾åº¦è®­ç»ƒä½ çš„æ¨¡å‹ï¼Œè®­ç»ƒå‡ºæ¥çš„ç¥ç»ç½‘ç»œå¯ä»¥ï¼š</a></p>
<ul>
<li>è¿è¡Œé€Ÿåº¦å¿«2-4å€</li>
<li>å‡ è¡Œä»£ç å°±å¯ä»¥çœä¸‹ä¸€ç¬”ä¹°æ–°å†…å­˜çš„é’±</li>
</ul>
<h2 id="Apex"><a href="#Apex" class="headerlink" title="Apex"></a>Apex</h2><p>nvidiaç»´æŠ¤çš„å·¥å…·ç®€åŒ–äº†Pytorchä¸­çš„æ··åˆç²¾åº¦å’Œåˆ†å¸ƒå¼åŸ¹è®­ã€‚è¿™é‡Œçš„ä¸€äº›ä»£ç æœ€ç»ˆå°†åŒ…å«åœ¨ä¸Šæ¸¸Pytorchä¸­ã€‚Apexçš„ç›®çš„æ˜¯å°½å¿«ä¸ºç”¨æˆ·æä¾›æœ€æ–°çš„å®ç”¨å·¥å…·ã€‚</p>
<h2 id="apex-amp"><a href="#apex-amp" class="headerlink" title="apex.amp"></a>apex.amp</h2><p>Ampå…è®¸ç”¨æˆ·è½»æ¾åœ°å°è¯•ä¸åŒçš„çº¯æ¨¡å¼å’Œæ··åˆç²¾åº¦æ¨¡å¼ã€‚é€šè¿‡é€‰æ‹©â€œä¼˜åŒ–çº§â€æˆ–opt_levelé€‰æ‹©å¸¸ç”¨çš„é»˜è®¤æ¨¡å¼;æ¯ä¸ªopt_levelå»ºç«‹ä¸€ç»„å±æ€§æ¥ç®¡ç†Ampå®ç°çš„çº¯ç²¾åº¦æˆ–æ··åˆç²¾åº¦è®­ç»ƒã€‚é€šè¿‡å°†ç‰¹å®šå±æ€§çš„å€¼ç›´æ¥ä¼ é€’ç»™amp.initializeï¼Œå¯ä»¥å®ç°å¯¹ç»™å®šopt_levelè¡Œä¸ºæ–¹å¼çš„ç»†ç²’åº¦æ§åˆ¶ã€‚è¿™äº›æ‰‹åŠ¨æŒ‡å®šçš„å€¼è¦†ç›–opt_levelå»ºç«‹çš„é»˜è®¤å€¼ã€‚</p>
<p>ğŸŒ°:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Declare model and optimizer as usual, with default (FP32) precision</span></span><br><span class="line">model = torch.nn.Linear(D_in, D_out).cuda()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Allow Amp to perform casts as required by the opt_level</span></span><br><span class="line">model, optimizer = amp.initialize(model, optimizer, opt_level=<span class="string">"O1"</span>)</span><br><span class="line">...</span><br><span class="line"><span class="comment"># loss.backward() becomes:</span></span><br><span class="line"><span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">    scaled_loss.backward()</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>æå®æ¯…</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandaså…¥é—¨</title>
    <url>/2020/03/20/Pandas%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h1><h2 id="æ•°æ®ç±»å‹"><a href="#æ•°æ®ç±»å‹" class="headerlink" title="æ•°æ®ç±»å‹"></a>æ•°æ®ç±»å‹</h2><p>Pandasä¸­çš„åŸºç¡€æ•°æ®ç±»å‹æœ‰Serieså’ŒDataFrameï¼Œå…¶ä¸­ï¼ŒSerieså…·æœ‰ä¸€ç»´ç´¢å¼•ï¼ˆè¡Œç´¢å¼•ï¼‰ï¼ŒDataFrameå…·æœ‰äºŒç»´ç´¢å¼•ï¼ˆè¡Œç´¢å¼•å’Œåˆ—ç´¢å¼•ï¼‰ã€‚</p>
<h3 id="Series"><a href="#Series" class="headerlink" title="Series"></a>Series</h3><p>æ—¢ç„¶æ˜¯ä¸€ç»´ç´¢å¼•ï¼Œå°±è¦æœ‰key,valueå¯¹ï¼Œå¯ä»¥ç›´æ¥ä¼ å…¥ä¸€ä¸ªdictã€‚é€šè¿‡ä¸€ä¸ªkeyï¼Œå°±å¯ä»¥ç¡®å®šä¸€ä¸ªvalueã€‚<br><code>s = pd.Series({&#39;a&#39;: 10, &#39;b&#39;: 20, &#39;c&#39;: 30})</code></p>
<h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><p>éœ€è¦è¡Œå’Œåˆ—æ‰å¯ä»¥ç¡®å®šä¸€ä¸ªå…ƒç´ ã€‚<br>å¯ä»¥æŒ‰åˆ—ä¼ å…¥</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">12df &#x3D; pd.DataFrame(&#123;&#39;one&#39;: pd.Series([1, 2, 3]),</span><br><span class="line">                   &#39;two&#39;: pd.Series([4, 5, 6])&#125;)</span><br></pre></td></tr></table></figure>

<p>ä¹Ÿå¯ä»¥æŒ‰è¡Œä¼ å…¥</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">123df &#x3D; pd.DataFrame([&#123;&#39;one&#39;: 1, &#39;two&#39;: 4&#125;,</span><br><span class="line">                   &#123;&#39;one&#39;: 2, &#39;two&#39;: 5&#125;,</span><br><span class="line">                   &#123;&#39;one&#39;: 3, &#39;two&#39;: 6&#125;])</span><br></pre></td></tr></table></figure>

<h2 id="æ•°æ®è¯»å–"><a href="#æ•°æ®è¯»å–" class="headerlink" title="æ•°æ®è¯»å–"></a>æ•°æ®è¯»å–</h2><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/io.html" target="_blank" rel="noopener">Input/output â€” pandas 1.0.1 documentation</a></p>
<h3 id="è¯»å–csv"><a href="#è¯»å–csv" class="headerlink" title="è¯»å–csv"></a>è¯»å–csv</h3><p><code>f = pd.read_csv()</code><br><img src="/" alt class="lazyload" data-src="/2020/03/20/Pandas%E5%85%A5%E9%97%A8/1.png"></p>
<h2 id="åŸºæœ¬æ“ä½œ"><a href="#åŸºæœ¬æ“ä½œ" class="headerlink" title="åŸºæœ¬æ“ä½œ"></a>åŸºæœ¬æ“ä½œ</h2><ul>
<li><code>df.head()</code>æ˜¾ç¤ºæ–‡ä»¶å¤´éƒ¨</li>
<li><code>df.tail()</code>æ˜¾ç¤ºæ–‡ä»¶å°¾éƒ¨</li>
<li><code>df.describe()</code>æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ</li>
<li><code>df.values</code>å°†DataFrameè½¬æ¢ä¸ºnumpyæ•°ç»„</li>
<li><code>df.index</code>è¡Œç´¢å¼•</li>
<li><code>df.columns</code>åˆ—ç´¢å¼•</li>
<li><code>df.shape</code>DataFrameå½¢çŠ¶<br>æ‰€æœ‰å±æ€§ï¼š<a href="https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#attributes-and-underlying-data" target="_blank" rel="noopener">DataFrame â€” pandas 1.0.1 documentation</a></li>
</ul>
<h2 id="æ•°æ®é€‰æ‹©"><a href="#æ•°æ®é€‰æ‹©" class="headerlink" title="æ•°æ®é€‰æ‹©"></a>æ•°æ®é€‰æ‹©</h2><p>æ•°æ®é€‰æ‹©å°±æ˜¯å°†åŸå§‹æ•°æ®ä¸­çš„ä¸€éƒ¨åˆ†æ‹¿å‡ºæ¥ï¼Œç”¨äºåç»­å¤„ç†æ­¥éª¤</p>
<h3 id="åŸºäºç´¢å¼•æ•°å­—é€‰æ‹©"><a href="#åŸºäºç´¢å¼•æ•°å­—é€‰æ‹©" class="headerlink" title="åŸºäºç´¢å¼•æ•°å­—é€‰æ‹©"></a>åŸºäºç´¢å¼•æ•°å­—é€‰æ‹©</h3><ul>
<li><code>df.iloc[:3]</code> é€‰æ‹©å‰ä¸‰è¡Œ</li>
<li><code>df.iloc[5]</code>é€‰æ‹©æŸä¸€è¡Œ</li>
<li><code>df.iloc[[è¡Œ], [åˆ—]]</code> å…¶ä¸­ï¼Œè¡Œå’Œåˆ—éƒ½å¯ä»¥æ˜¯list</li>
<li><code>df.iloc[:ï¼Œ1:4]</code>é€‰æ‹©2åˆ°4åˆ—ï¼ˆåˆ‡ç‰‡æ—¶å·¦é—­å³å¼€ï¼‰</li>
</ul>
<h3 id="åŸºäºæ ‡ç­¾çš„é€‰æ‹©-åˆ‡ç‰‡æ—¶å·¦å³éƒ½é—­"><a href="#åŸºäºæ ‡ç­¾çš„é€‰æ‹©-åˆ‡ç‰‡æ—¶å·¦å³éƒ½é—­" class="headerlink" title="åŸºäºæ ‡ç­¾çš„é€‰æ‹©(åˆ‡ç‰‡æ—¶å·¦å³éƒ½é—­)"></a>åŸºäºæ ‡ç­¾çš„é€‰æ‹©(åˆ‡ç‰‡æ—¶å·¦å³éƒ½é—­)</h3><ul>
<li><code>df.loc[0:2]</code>é€‰æ‹©å‰ä¸‰è¡Œ</li>
<li><code>df.loc[[0,2,4]]</code>é€‰æ‹©1ã€3ã€5è¡Œ</li>
<li><code>df.loc[:,&#39;Total Population&#39;:&#39;Total Males&#39;]</code></li>
<li><code>df.loc[[0, 2], &#39;Median Age&#39;:]</code>é€‰æ‹©1ã€3è¡Œçš„â€™Median Ageâ€™åé¢çš„åˆ—</li>
</ul>
<h3 id="æ•°æ®åˆ å‡"><a href="#æ•°æ®åˆ å‡" class="headerlink" title="æ•°æ®åˆ å‡"></a>æ•°æ®åˆ å‡</h3><ul>
<li><p><code>df.drop(labels=[&#39;Median Age&#39;, &#39;Total Males&#39;], axis = 1)</code>åˆ é™¤ä¸¤ä¸ªæŒ‡å®šåˆ—</p>
</li>
<li><p><code>df.drop(labels=[0, 1], axis = 0)</code>åˆ é™¤0ã€1è¡Œ</p>
</li>
<li><p><code>df.drop_dupicates()</code>æ•°æ®å»é‡</p>
</li>
<li><p><code>df.dropna()</code>æ•°æ®å»ç©ºå€¼</p>
</li>
<li><p><code>df.insert(value = è¦æ’å…¥çš„å€¼, loc=åˆ—å·ï¼Œcolumn = &#39;åˆ—å&#39;)</code>åœ¨DataFrameä¸­æ’å…¥åå­—å«â€™åˆ—åâ€™ï¼Œå€¼ä¸ºvalueçš„ä¸€åˆ—ã€‚</p>
</li>
<li><p><code>df.isna()</code>è¿”å›bool</p>
</li>
<li><p><code>df.notna()</code>è¿”å›boolåˆ—è¡¨<br>å¡«å……ç¼ºå¤±å€¼</p>
</li>
<li><p><code>df.fillna()</code></p>
</li>
<li><p><code>df.fillna(method=&#39;pad&#39;)</code>ä½¿ç”¨å‰é¢çš„å€¼å¡«å……ç©ºå€¼</p>
</li>
<li><p>â€˜df.fillna(method=â€˜bfillâ€™)â€™ä½¿ç”¨åé¢çš„å€¼å¡«å……</p>
</li>
<li><p><code>df.fillna(df.mean()[&#39;C&#39;:&#39;E&#39;])</code>ä½¿ç”¨å¹³å‡å€¼å¡«å……<br>æ’å€¼å¡«å……</p>
</li>
<li><pre><code>df.interpolate(method=)</code></pre><ul>
<li><code>method=&#39;quadratic&#39;</code>æ•°æ®å¢é•¿é€Ÿç‡è¶Šæ¥è¶Šå¿«</li>
<li><code>method=&#39;pchip&#39;</code>ç´¯è®¡åˆ†å¸ƒ</li>
<li><code>method=&#39;akima&#39;</code>ä»¥å¹³æ»‘ç»˜å›¾ä¸ºç›®çš„<br>ç»˜å›¾</li>
</ul>
</li>
<li><p>df.plot(kind=â€˜barâ€™â€¦)ç›´æ¥ç»˜å›¾<br>å…¶å®ƒ</p>
</li>
<li><p>æ•°æ®è®¡ç®— <a href="https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#binary-operator-functions" target="_blank" rel="noopener">DataFrame â€” pandas 1.0.1 documentation</a></p>
</li>
<li><p>æ•°æ®èšåˆ <a href="https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#function-application-groupby-window" target="_blank" rel="noopener">DataFrame â€” pandas 1.0.1 documentation</a></p>
</li>
<li><p>ç»Ÿè®¡åˆ†æ <a href="https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats" target="_blank" rel="noopener">DataFrame â€” pandas 1.0.1 documentation</a></p>
</li>
<li><p>æ—¶é—´åºåˆ— <a href="https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#time-series-related" target="_blank" rel="noopener">DataFrame â€” pandas 1.0.1 documentation</a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>Pandas</tag>
      </tags>
  </entry>
</search>
